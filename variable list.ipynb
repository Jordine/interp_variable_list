{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d16916-9fa7-47ad-b3c8-939e18267221",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/neelnanda-io/TransformerLens -q --quiet\n",
    "!pip install circuitsvis -q --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d7b01c-8845-4190-9bc9-b76679438e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import transformer_lens\n",
    "except:\n",
    "    !pip install git+https://github.com/neelnanda-io/TransformerLens -q --quiet\n",
    "    !pip install circuitsvis -q --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f2620a-bd8e-4512-9e16-e8a1bdf4529b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7567542e-4320\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7567542e-4320\",\n",
       "      Hello,\n",
       "      {\"name\": \"You\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x2825f789d30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime as dt\n",
    "from itertools import repeat\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from typing import cast, Generator, Literal\n",
    "from copy import deepcopy\n",
    "\n",
    "import circuitsvis as cv\n",
    "from fancy_einsum import einsum\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, tensor, Tensor, TensorType as TT\n",
    "from torch.nn import functional as F\n",
    "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self\n",
    "\n",
    "cv.examples.hello(\"You\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7242ec18-dd68-4011-9233-7439cf62f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable hyperparameters\n",
    "MIN_LIST_LENGTH = 2\n",
    "MAX_LIST_LENGTH = 50\n",
    "\n",
    "# Context length: [start, *(unsorted_)list_length, mid, *(sorted_)list_length]\n",
    "N_CTX = 2 * MAX_LIST_LENGTH + 2\n",
    "\n",
    "# Size of vocabulary\n",
    "D_VOCAB = 66\n",
    "\n",
    "# Should lists have repetitions?\n",
    "ALLOW_REPETITIONS = False\n",
    "\n",
    "# Attention only? (False -> model includes MLPs)\n",
    "ATTN_ONLY = True\n",
    "\n",
    "# Model dimenions\n",
    "N_LAYERS = 1\n",
    "N_HEADS = 1\n",
    "D_MODEL = 128\n",
    "D_HEAD = 32\n",
    "D_MLP = None\n",
    "\n",
    "if ATTN_ONLY:\n",
    "    D_MLP = None\n",
    "\n",
    "# Default batch size\n",
    "DEFAULT_BATCH_SIZE = 32\n",
    "\n",
    "# If you want to use pretrained weights, replace None by the path to the pkl file.\n",
    "path_pkl_pretrained_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c09a8a6-c383-4765-8bba-995f4cbfe717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MID_TOKEN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd37d5e-a756-4b35-b8bc-dd49466e5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_TOKEN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d07435-faf1-44d2-93ca-e8dd86727e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = 'cpu'\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{DEVICE = }\")\n",
    "\n",
    "# Seeds to generate training, validation, and test data\n",
    "TRAIN_SEED = 42\n",
    "VAL_SEED = 66\n",
    "TEST_SEED = 1729\n",
    "\n",
    "\n",
    "# \"Real\" tokens range from 0 to D_VOCAB - 2 (non-inclusive)\n",
    "VOCAB_MIN_ID = 0\n",
    "VOCAB_MAX_ID = D_VOCAB - 2\n",
    "\n",
    "# START token is D_VOCAB - 2 and MID token is D_VOCAB - 1\n",
    "START_TOKEN_ID = D_VOCAB - 2\n",
    "MID_TOKEN_ID = D_VOCAB - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f05c95-3774-4ce7-a34b-ce5db4679183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_MAX_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bcacc50-6b85-4a42-b1cc-8891f999a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "496de44a-50d3-4c70-8230-530c626bdc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_VALUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f750cfe4-5bcb-417c-8cb6-1c62fae12dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64,  3, 38, 11, 10, 59, 31, 17, 40, 36, 50,  6,  8, 24, 30, 47, 57, 52,\n",
      "        20, 16, 29, 37, 62, 61, 42, 46, 54,  7, 43, 63, 28, 60,  1, 48, 32, 34,\n",
      "         2, 65,  1,  2,  3,  6,  7,  8, 10, 11, 16, 17, 20, 24, 28, 29, 30, 31,\n",
      "        32, 34, 36, 37, 38, 40, 42, 43, 46, 47, 48, 50, 52, 54, 57, 59, 60, 61,\n",
      "        62, 63, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "torch.Size([102])\n"
     ]
    }
   ],
   "source": [
    "# Function to generate lists with variable length\n",
    "def generate_list(batch_size: int) -> Tuple[Tensor, Tensor]:\n",
    "    lengths = torch.randint(MIN_LIST_LENGTH, MAX_LIST_LENGTH + 1, (batch_size,))\n",
    "    lists = [torch.randperm(VOCAB_MAX_ID)[:length] for length in lengths]\n",
    "    return pad_sequence(lists, batch_first=True, padding_value=PADDING_VALUE).to(DEVICE), lengths\n",
    "\n",
    "# General generator\n",
    "def make_data_gen(\n",
    "    *,\n",
    "    batch_size: int = DEFAULT_BATCH_SIZE,\n",
    "    dataset: Literal[\"train\", \"val\", \"test\"],\n",
    ") -> Generator[Tensor, None, None]:\n",
    "    assert dataset in (\"train\", \"val\", \"test\")\n",
    "    seed = TRAIN_SEED if dataset == \"train\" else VAL_SEED if dataset == \"val\" else TEST_SEED\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    while True:\n",
    "        x_padded, lengths = generate_list(batch_size)\n",
    "        \n",
    "        # Compute sorted x without considering padding value \n",
    "        x_without_padding = [x_padded[i, :length] for i, length in enumerate(lengths)]\n",
    "        x_sorted = [torch.sort(xi)[0] for xi in x_without_padding]\n",
    "        x_sorted_padded = pad_sequence(x_sorted, batch_first=True, padding_value=PADDING_VALUE).to(DEVICE)\n",
    "\n",
    "        # Create sequences\n",
    "        x_start = START_TOKEN_ID * torch.ones(batch_size, 1, dtype=torch.long).to(DEVICE)\n",
    "        x_mid = MID_TOKEN_ID * torch.ones(batch_size, 1, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "        sequences = []\n",
    "        for i in range(batch_size):\n",
    "            unsorted_list = x_without_padding[i]\n",
    "            sorted_list = x_sorted[i]\n",
    "            length = len(unsorted_list)\n",
    "            padded_length = sorted_list.numel() - unsorted_list.numel()\n",
    "            \n",
    "            # Concatenate start token, unsorted list, mid token, sorted list\n",
    "            sequence = torch.cat(\n",
    "                [x_start[i], unsorted_list, x_mid[i], sorted_list,\n",
    "                torch.full((max(0, MAX_LIST_LENGTH - length),), PADDING_VALUE, dtype=torch.long).to(DEVICE)]\n",
    "            )\n",
    "            sequences.append(sequence)\n",
    "\n",
    "        full_seq_padded = pad_sequence(sequences, batch_first=True, padding_value=PADDING_VALUE).to(DEVICE)\n",
    "\n",
    "        yield full_seq_padded\n",
    "\n",
    "# Training data generator (kinda wrapper)\n",
    "def make_train_gen() -> Generator[Tensor, None, None]:\n",
    "    \"\"\"Make generator of training data\"\"\"\n",
    "    return make_data_gen(batch_size=128, dataset=\"train\")\n",
    "\n",
    "# Validation and test data\n",
    "val_data = next(make_data_gen(batch_size=1000, dataset=\"val\"))\n",
    "test_data = next(make_data_gen(batch_size=1000, dataset=\"test\"))\n",
    "\n",
    "# Let's print one example to verify\n",
    "print(val_data[1])\n",
    "print(val_data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f87a0b-334f-468e-9abd-fafcf90e09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "def loss_fn(\n",
    "    logits: Tensor,  # [batch, pos, d_vocab]\n",
    "    tokens: Tensor,  # [batch, pos]\n",
    "    lengths: Tensor,  # [batch] - lengths of each sequence\n",
    "    padding_value: int = -1,\n",
    "    return_per_token: bool = False\n",
    ") -> Tensor:  # scalar\n",
    "    \"\"\"\n",
    "    Compute the loss for a variable-length problem, considering padding tokens.\n",
    "    - Ignore padding tokens in the loss computation.\n",
    "    \"\"\"\n",
    "    # Get the batch size and sequence length\n",
    "    batch_size, seq_length = tokens.size()\n",
    "\n",
    "    # Initialize a tensor to store the correct log probabilities for each batch\n",
    "    correct_log_probs_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Get the length of the sequence without padding\n",
    "        seq_len = lengths[i].item()\n",
    "\n",
    "        # Slice logits and tokens\n",
    "        logits_sorted = logits[i, :seq_len]\n",
    "        tokens_sorted = tokens[i, :seq_len]\n",
    "\n",
    "        # Compute log probabilities\n",
    "        log_probs_sorted = logits_sorted.log_softmax(-1)\n",
    "\n",
    "        # Get the correct log probabilities for the sorted part, ignoring padding positions\n",
    "        correct_log_probs = log_probs_sorted.gather(-1, tokens_sorted[..., None])[..., 0]\n",
    "\n",
    "        # Generate mask for non-padding tokens\n",
    "        mask = (tokens_sorted != padding_value).float()\n",
    "\n",
    "        # Append to list\n",
    "        correct_log_probs_list.append(correct_log_probs * mask)\n",
    "        mask_list.append(mask)\n",
    "\n",
    "    # Stack the correct log probabilities and masks to get a tensor of shape [batch, variable_pos]\n",
    "    correct_log_probs_tensor = torch.cat(correct_log_probs_list)\n",
    "    mask_tensor = torch.cat(mask_list)\n",
    "\n",
    "    if return_per_token:\n",
    "        # Divide only by the number of non-padding tokens\n",
    "        num_non_padding_tokens = mask_tensor.sum()\n",
    "        return -correct_log_probs_tensor.sum() / num_non_padding_tokens\n",
    "    else:\n",
    "        # Element-wise mean of the correct log probs, ignoring paddings\n",
    "        return -correct_log_probs_tensor.sum() / mask_tensor.sum()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `logits`, `tokens`, and `lengths` are provided from the model output and data loader\n",
    "# logits: [batch_size, sequence_length, d_vocab]\n",
    "# tokens: [batch_size, sequence_length]\n",
    "# lengths: [batch_size]\n",
    "\n",
    "\n",
    "test = \"\"\"\n",
    "# Create some example data to test the function\n",
    "logits = torch.randn(3, 42, 66)  # example logits with batch_size 3, seq_length 42, d_vocab 66\n",
    "tokens = torch.tensor([\n",
    "    [64, 3, 38, 11, 10, 59, 31, 17, 40, 36, 50, 65, 3, 10, 11, 17, 31, 36, 38, 40, 50, 59, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [12, 52, 24, 36, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [65, 50, 36, 40, 10, 3, 59, 38, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "]) \n",
    "lengths = torch.tensor([21, 4, 9])\n",
    "\n",
    "# Compute the loss\n",
    "loss = loss_fn(logits, tokens, lengths)\n",
    "print(loss)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995ef6ac-71a7-4ed2-b75e-d62a99577832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Accuracy: 0.00%\n",
      "Token Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from torch import Tensor\n",
    "\n",
    "def acc_fn(\n",
    "    logits: Tensor,  # [batch, pos, d_vocab]\n",
    "    tokens: Tensor,  # [batch, pos]\n",
    "    lengths: Tensor,  # [batch]\n",
    "    padding_value: int = -1,\n",
    "    per: Literal[\"token\", \"sequence\"] = \"sequence\"\n",
    ") -> float:\n",
    "    \"\"\"Compute accuracy as percentage of correct predictions.\"\"\"\n",
    "    batch_size, seq_length = tokens.size()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "    total_sequences = 0\n",
    "    correct_sequences = 0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        length = lengths[i].item()\n",
    "\n",
    "        # Slicing logits and tokens to exclude padding regions and only consider valid lengths\n",
    "        logits_sorted = logits[i, 1 + length + 1:1 + 2 * length + 1]  # [START | unsorted | MID | sorted | PADDING]\n",
    "        tokens_sorted = tokens[i, 1 + length + 1:1 + 2 * length + 1]\n",
    "\n",
    "        preds = logits_sorted.argmax(-1)\n",
    "\n",
    "        if per == \"sequence\":\n",
    "            is_sequence_correct = (preds == tokens_sorted).all().item()\n",
    "            correct_sequences += is_sequence_correct\n",
    "            total_sequences += 1\n",
    "        else:\n",
    "            mask = (tokens_sorted != padding_value)\n",
    "            correct_tokens = (preds == tokens_sorted) * mask\n",
    "            total_correct += correct_tokens.sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "    if per == \"sequence\":\n",
    "        return correct_sequences / total_sequences if total_sequences > 0 else 0.0\n",
    "    else:\n",
    "        return total_correct / total_tokens if total_tokens > 0 else 0.0\n",
    "\n",
    "# Example tensors for testing\n",
    "import torch\n",
    "logits = torch.randn(3, 42, 66)  # Example logits with batch_size 3, seq_length 42, d_vocab 66\n",
    "tokens = torch.tensor([\n",
    "    [64, 3, 38, 11, 10, 59, 31, 17, 40, 36, 50, 65, 3, 10, 11, 17, 31, 36, 38, 40, 50, 59, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [12, 52, 24, 36, 65, 12, 24, 36, 52, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [65, 50, 36, 40, 10, 3, 59, 38, 11, 65, 3, 10, 11, 17, 31, 36, 38, 40, 50, 59, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "])\n",
    "lengths = torch.tensor([11, 4, 9])\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy_seq = acc_fn(logits, tokens, lengths, per=\"sequence\")\n",
    "print(f\"Sequence Accuracy: {accuracy_seq:.2%}\")\n",
    "\n",
    "accuracy_token = acc_fn(logits, tokens, lengths, per=\"token\")\n",
    "print(f\"Token Accuracy: {accuracy_token:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b13ad79d-d53f-47ea-a5f2-2080d08b9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Accuracy: 33.33%\n",
      "Token Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "seq_length = 42\n",
    "d_vocab = 66\n",
    "\n",
    "# Create tokens with sorted parts aligned\n",
    "tokens = torch.tensor([\n",
    "    [64, 3, 38, 11, 10, 59, 31, 17, 40, 36, 50, 65, 3, 10, 11, 17, 31, 36, 38, 40, 50, 59, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [12, 52, 24, 36, 65, 12, 24, 36, 52, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [65, 50, 36, 40, 10, 3, 59, 38, 11, 65, 3, 10, 11, 17, 31, 36, 38, 40, 50, 59, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "]).long()\n",
    "\n",
    "# Lengths for the sorted and unsorted lists for each sequence in the batch\n",
    "lengths = torch.tensor([11, 4, 9])\n",
    "\n",
    "# Logits array shaped [batch_size, seq_length, d_vocab]\n",
    "logits = torch.full((batch_size, seq_length, d_vocab), -100.0)  # Initialize with low logit values\n",
    "\n",
    "for i in range(batch_size):\n",
    "    length = lengths[i].item()\n",
    "    sorted_start_pos = 1 + length + 1\n",
    "    \n",
    "    # Set high logits to ensure correct predictions\n",
    "    for j in range(length):\n",
    "        tokens_val = tokens[i, sorted_start_pos + j].item()  # Get the token value to match\n",
    "        logits[i, sorted_start_pos + j, tokens_val] = 10.0   # Assign high logit to correct token\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy_seq = acc_fn(logits, tokens, lengths, per=\"sequence\")\n",
    "print(f\"Sequence Accuracy: {accuracy_seq:.2%}\")\n",
    "\n",
    "accuracy_token = acc_fn(logits, tokens, lengths, per=\"token\")\n",
    "print(f\"Token Accuracy: {accuracy_token:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "966a2fca-90bd-4ab3-82a8-5b94b143c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=N_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    "    d_head=D_HEAD,\n",
    "    n_ctx=N_CTX,\n",
    "    d_vocab=D_VOCAB,\n",
    "    act_fn=\"relu\",\n",
    "    seed=42,\n",
    "    device=DEVICE,\n",
    "    attn_only=ATTN_ONLY\n",
    ")\n",
    "model = HookedTransformer(cfg, move_to_device=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe5ed42-7dcd-479f-ab37-e18dcd6df5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced80799-b790-4db6-bdea-70f7686f8a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d438062-e405-49f0-8e12-e47968dc6dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64, 33, 62, 11, 41, 18, 61, 39, 59, 45, 29, 40, 43, 13, 49, 26,  9, 53,\n",
      "        63, 51, 23, 52, 24,  5, 35, 16, 60, 65,  5,  9, 11, 13, 16, 18, 23, 24,\n",
      "        26, 29, 33, 35, 39, 40, 41, 43, 45, 49, 51, 52, 53, 59, 60, 61, 62, 63,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "torch.Size([102])\n",
      "tensor(26)\n"
     ]
    }
   ],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingHistory:\n",
    "    losses: List[float]\n",
    "    train_accuracies: List[float]\n",
    "    val_accuracies: List[float]\n",
    "\n",
    "def converged(val_accs: List[float], n_last: int = 10) -> bool:\n",
    "    return cast(bool, (torch.tensor(val_accs[-n_last:]) == 1).all().item())\n",
    "\n",
    "def generate_list(batch_size: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    lengths = torch.randint(MIN_LIST_LENGTH, MAX_LIST_LENGTH + 1, (batch_size,))\n",
    "    lists = [torch.randperm(VOCAB_MAX_ID)[:length] for length in lengths]\n",
    "    return pad_sequence(lists, batch_first=True, padding_value=PADDING_VALUE).to(DEVICE), lengths\n",
    "\n",
    "def make_data_gen(batch_size: int, dataset: str) -> Generator[Tuple[torch.Tensor, torch.Tensor], None, None]:\n",
    "    assert dataset in (\"train\", \"val\", \"test\")\n",
    "    seed = 0 if dataset == \"train\" else 1 if dataset == \"val\" else 2  # Simplified seeds\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    while True:\n",
    "        x_padded, lengths = generate_list(batch_size)\n",
    "\n",
    "        x_without_padding = [x_padded[i, :length] for i, length in enumerate(lengths)]\n",
    "        x_sorted = [torch.sort(xi)[0] for xi in x_without_padding]\n",
    "        x_sorted_padded = pad_sequence(x_sorted, batch_first=True, padding_value=PADDING_VALUE).to(DEVICE)\n",
    "\n",
    "        x_start = START_TOKEN_ID * torch.ones(batch_size, 1, dtype=torch.long).to(DEVICE)\n",
    "        x_mid = MID_TOKEN_ID * torch.ones(batch_size, 1, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "        sequences = []\n",
    "        lengths_seq = []\n",
    "        for i in range(batch_size):\n",
    "            unsorted_list = x_without_padding[i]\n",
    "            sorted_list = x_sorted[i]\n",
    "            length = len(unsorted_list)\n",
    "\n",
    "            sequence = torch.cat(\n",
    "                [x_start[i], unsorted_list, x_mid[i], sorted_list,\n",
    "                torch.full((MAX_LIST_LENGTH - length,), PADDING_VALUE, dtype=torch.long).to(DEVICE)]\n",
    "            )\n",
    "            sequences.append(sequence)\n",
    "            lengths_seq.append(length)\n",
    "\n",
    "        full_seq_padded = pad_sequence(sequences, batch_first=True, padding_value=PADDING_VALUE).to(DEVICE)\n",
    "        yield full_seq_padded, torch.tensor(lengths_seq).to(DEVICE)\n",
    "\n",
    "def make_train_gen() -> Generator[Tuple[torch.Tensor, torch.Tensor], None, None]:\n",
    "    return make_data_gen(batch_size=128, dataset=\"train\")\n",
    "\n",
    "# Taking length info along with val_data\n",
    "val_data = next(make_data_gen(batch_size=1000, dataset=\"val\"))\n",
    "\n",
    "print(val_data[0][1])\n",
    "print(val_data[0][1].shape)\n",
    "print(val_data[1][1])  # Checking the lengths\n",
    "\n",
    "def train_model(model: HookedTransformer) -> TrainingHistory:\n",
    "    model.to(DEVICE)\n",
    "    lr = 1e-4  # Reduced from 1e-3\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min', patience=100)\n",
    "\n",
    "    losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    train_gen = make_train_gen()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        tokens, lengths = next(train_gen)\n",
    "\n",
    "        logits = model(tokens)\n",
    "\n",
    "        loss = loss_fn(logits, tokens, lengths)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            losses.append(loss.item())\n",
    "            train_batch_acc = acc_fn(logits, tokens, lengths)\n",
    "            val_acc, val_loss = validate_model(model, val_data)\n",
    "\n",
    "            train_accuracies.append(train_batch_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            print(\n",
    "                f\"Epoch {epoch}/{n_epochs} ({epoch / n_epochs:.0%}) : \"\n",
    "                f\"loss = {loss.item():.4f}; {train_batch_acc=:.3%}; \"\n",
    "                f\"{val_acc=:.3%}; lr={scheduler._last_lr[0]}\"  # type:ignore\n",
    "            )\n",
    "            if converged(val_accuracies):\n",
    "                print(f\"\\nAchieved consistent perfect validation accuracy after {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "    return TrainingHistory(losses, train_accuracies, val_accuracies)\n",
    "\n",
    "def validate_model(model: HookedTransformer, val_data: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[float, float]:\n",
    "    val_tokens, val_lengths = val_data\n",
    "    val_logits = model(val_tokens.to(DEVICE))\n",
    "    val_loss = loss_fn(val_logits, val_tokens.to(DEVICE), val_lengths.to(DEVICE))\n",
    "    val_acc = acc_fn(val_logits, val_tokens.to(DEVICE), val_lengths.to(DEVICE))\n",
    "    return val_acc, val_loss.item()\n",
    "\n",
    "def load_model_state(model: HookedTransformer, filename: str) -> None:\n",
    "    assert os.path.isdir(\"models\"), \"Make a directory `models` with model state dicts\"\n",
    "    if not filename.startswith(\"models/\"):\n",
    "        filename = f\"models/{filename}\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        state_dict = pickle.load(f)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bdb2b2b-c18d-4513-855e-122d992441bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 102])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0c4e2-84a7-4d02-95c2-e7cbf0a1413f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f94055cf-f07a-4c55-ae89-ca17e3b9ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Epoch 0/20000 (0%) : loss = 4.5133; train_batch_acc=0.000%; val_acc=0.000%; lr=0.0001\n",
      "Epoch 100/20000 (0%) : loss = 2.7955; train_batch_acc=0.000%; val_acc=0.200%; lr=0.0001\n",
      "Epoch 200/20000 (1%) : loss = 1.2673; train_batch_acc=37.500%; val_acc=36.700%; lr=0.0001\n",
      "Epoch 300/20000 (2%) : loss = 0.3909; train_batch_acc=77.344%; val_acc=84.000%; lr=0.0001\n",
      "Epoch 400/20000 (2%) : loss = 0.1461; train_batch_acc=96.875%; val_acc=93.700%; lr=0.0001\n",
      "Epoch 500/20000 (2%) : loss = 0.0753; train_batch_acc=92.188%; val_acc=96.000%; lr=0.0001\n",
      "Epoch 600/20000 (3%) : loss = 0.0474; train_batch_acc=96.094%; val_acc=96.500%; lr=0.0001\n",
      "Epoch 700/20000 (4%) : loss = 0.0336; train_batch_acc=95.312%; val_acc=96.900%; lr=0.0001\n",
      "Epoch 800/20000 (4%) : loss = 0.0256; train_batch_acc=95.312%; val_acc=97.100%; lr=0.0001\n",
      "Epoch 900/20000 (4%) : loss = 0.0199; train_batch_acc=98.438%; val_acc=97.300%; lr=0.0001\n",
      "Epoch 1000/20000 (5%) : loss = 0.0164; train_batch_acc=91.406%; val_acc=97.700%; lr=0.0001\n",
      "Epoch 1100/20000 (6%) : loss = 0.0138; train_batch_acc=96.875%; val_acc=97.900%; lr=0.0001\n",
      "Epoch 1200/20000 (6%) : loss = 0.0115; train_batch_acc=96.094%; val_acc=97.800%; lr=0.0001\n",
      "Epoch 1300/20000 (6%) : loss = 0.0100; train_batch_acc=97.656%; val_acc=97.900%; lr=0.0001\n",
      "Epoch 1400/20000 (7%) : loss = 0.0088; train_batch_acc=96.875%; val_acc=97.800%; lr=0.0001\n",
      "Epoch 1500/20000 (8%) : loss = 0.0076; train_batch_acc=99.219%; val_acc=97.900%; lr=0.0001\n",
      "Epoch 1600/20000 (8%) : loss = 0.0068; train_batch_acc=98.438%; val_acc=98.000%; lr=0.0001\n",
      "Epoch 1700/20000 (8%) : loss = 0.0060; train_batch_acc=98.438%; val_acc=98.000%; lr=0.0001\n",
      "Epoch 1800/20000 (9%) : loss = 0.0054; train_batch_acc=96.094%; val_acc=98.100%; lr=0.0001\n",
      "Epoch 1900/20000 (10%) : loss = 0.0049; train_batch_acc=99.219%; val_acc=98.100%; lr=0.0001\n",
      "Epoch 2000/20000 (10%) : loss = 0.0044; train_batch_acc=98.438%; val_acc=98.100%; lr=0.0001\n",
      "Epoch 2100/20000 (10%) : loss = 0.0040; train_batch_acc=95.312%; val_acc=98.100%; lr=0.0001\n",
      "Epoch 2200/20000 (11%) : loss = 0.0037; train_batch_acc=95.312%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2300/20000 (12%) : loss = 0.0034; train_batch_acc=97.656%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2400/20000 (12%) : loss = 0.0031; train_batch_acc=97.656%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2500/20000 (12%) : loss = 0.0028; train_batch_acc=97.656%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2600/20000 (13%) : loss = 0.0026; train_batch_acc=99.219%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2700/20000 (14%) : loss = 0.0024; train_batch_acc=98.438%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2800/20000 (14%) : loss = 0.0023; train_batch_acc=96.094%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 2900/20000 (14%) : loss = 0.0021; train_batch_acc=98.438%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 3000/20000 (15%) : loss = 0.0020; train_batch_acc=97.656%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3100/20000 (16%) : loss = 0.0018; train_batch_acc=96.094%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3200/20000 (16%) : loss = 0.0017; train_batch_acc=96.875%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3300/20000 (16%) : loss = 0.0016; train_batch_acc=99.219%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3400/20000 (17%) : loss = 0.0015; train_batch_acc=97.656%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3500/20000 (18%) : loss = 0.0014; train_batch_acc=97.656%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3600/20000 (18%) : loss = 0.0013; train_batch_acc=96.094%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3700/20000 (18%) : loss = 0.0012; train_batch_acc=98.438%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 3800/20000 (19%) : loss = 0.0011; train_batch_acc=96.094%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 3900/20000 (20%) : loss = 0.0011; train_batch_acc=97.656%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 4000/20000 (20%) : loss = 0.0010; train_batch_acc=99.219%; val_acc=98.200%; lr=0.0001\n",
      "Epoch 4100/20000 (20%) : loss = 0.0009; train_batch_acc=99.219%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4200/20000 (21%) : loss = 0.0009; train_batch_acc=97.656%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4300/20000 (22%) : loss = 0.0008; train_batch_acc=98.438%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4400/20000 (22%) : loss = 0.0008; train_batch_acc=96.094%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4500/20000 (22%) : loss = 0.0007; train_batch_acc=97.656%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4600/20000 (23%) : loss = 0.0007; train_batch_acc=100.000%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4700/20000 (24%) : loss = 0.0007; train_batch_acc=99.219%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4800/20000 (24%) : loss = 0.0006; train_batch_acc=100.000%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 4900/20000 (24%) : loss = 0.0006; train_batch_acc=98.438%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 5000/20000 (25%) : loss = 0.0005; train_batch_acc=99.219%; val_acc=98.300%; lr=0.0001\n",
      "Epoch 5100/20000 (26%) : loss = 0.0005; train_batch_acc=98.438%; val_acc=98.400%; lr=0.0001\n",
      "Epoch 5200/20000 (26%) : loss = 0.0005; train_batch_acc=100.000%; val_acc=98.500%; lr=0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m   load_model_state(model, path_pkl_pretrained_weights)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m   history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 72\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m     70\u001b[0m     tokens, lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_gen)\n\u001b[1;32m---> 72\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, tokens, lengths)\n\u001b[0;32m     75\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformer_lens\\HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[1;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[0;32m    548\u001b[0m         )\n\u001b[1;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformer_lens\\components\\transformer_block.py:159\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[0;32m    152\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[0;32m    153\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[0;32m    155\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:195\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[1;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    169\u001b[0m     query_input: Union[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     position_bias: Optional[Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 head_index pos kv_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    shortformer_pos_embed is only used if self.cfg.positional_embedding_type == \"shortformer\", else defaults to None and is irrelevant. See HookedTransformerConfig for more details\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    past_kv_cache_entry is an optional entry of past keys and values for this layer, only relevant if generating text. Defaults to None\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m    additive_attention_mask is an optional mask to add to the attention weights. Defaults to None.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m    attention_mask is the attention mask for padded tokens. Defaults to None.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_qkv_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         kv_cache_pos_offset \u001b[38;5;241m=\u001b[39m past_kv_cache_entry\u001b[38;5;241m.\u001b[39mpast_keys\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:356\u001b[0m, in \u001b[0;36mAbstractAttention.calculate_qkv_matrices\u001b[1;34m(self, query_input, key_input, value_input)\u001b[0m\n\u001b[0;32m    340\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_q(\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;66;03m# call bitsandbytes method to dequantize and multiply\u001b[39;00m\n\u001b[0;32m    342\u001b[0m         bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_Q\n\u001b[0;32m    354\u001b[0m     )\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 356\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_q(\u001b[43mattn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_Q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_Q\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mload_in_4bit:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_K, Params4bit):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformer_lens\\utilities\\attention.py:17\u001b[0m, in \u001b[0;36msimple_attn_linear\u001b[1;34m(input, w, b)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_attn_linear\u001b[39m(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28minput\u001b[39m: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m     w: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_model d_head\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     14\u001b[0m     b: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_head\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos head_index d_head\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Linear layer for attention calculation.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead_index d_model d_head -> (head_index d_head) d_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     b_ \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_head -> (head_index d_head)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, w, b_)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\einops\\einops.py:591\u001b[0m, in \u001b[0;36mrearrange\u001b[1;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    537\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;124;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m \n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\einops\\einops.py:523\u001b[0m, in \u001b[0;36mreduce\u001b[1;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[0;32m    521\u001b[0m     shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mshape(tensor)\n\u001b[0;32m    522\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(axes_lengths), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[1;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhashable_axes_lengths\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    527\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error while processing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-reduction pattern \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(reduction, pattern)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\einops\\einops.py:244\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[1;34m(backend, recipe, tensor, reduction_type, axes_lengths)\u001b[0m\n\u001b[0;32m    242\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mreshape(tensor, init_shapes)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axes_reordering \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 244\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_reordering\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(reduced_axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    246\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m _reduce_axes(tensor, reduction_type\u001b[38;5;241m=\u001b[39mreduction_type, reduced_axes\u001b[38;5;241m=\u001b[39mreduced_axes, backend\u001b[38;5;241m=\u001b[39mbackend)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\einops\\_backends.py:257\u001b[0m, in \u001b[0;36mTorchBackend.transpose\u001b[1;34m(self, x, axes)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, axes):\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_gen = make_data_gen(batch_size=128, dataset=\"train\")\n",
    "\n",
    "\n",
    "if path_pkl_pretrained_weights:\n",
    "  load_model_state(model, path_pkl_pretrained_weights)\n",
    "else:\n",
    "  history = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b940b039-da3c-40b4-90c8-ecec53b7cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating on validation data:\n",
      "\tval_acc=98.500%\n",
      "\n",
      "Batch index 73:\n",
      "Unsorted: tensor([50, 43, 38, 19,  5, 16, 57, 21,  1, 35, 41, 36,  4, 46,  3, 54, 29,  0,\n",
      "        40, 18, 30, 14, 17,  6, 58,  7, 48, 10,  8, 20, 56, 44])\n",
      "Expected Sorted: tensor([ 0,  1,  3,  4,  5,  6,  7,  8, 10, 14, 16, 17, 18, 19, 20, 21, 29, 30,\n",
      "        35, 36, 38, 40, 41, 43, 44, 46, 48, 50, 54, 56, 57, 58])\n",
      "Predicted Sorted: tensor([ 0,  1,  3,  4,  5,  6,  7,  8, 10, 14, 16, 17, 18, 19, 20, 21, 29, 30,\n",
      "        35, 36, 38, 40, 41,  3, 44, 46, 48, 50, 54, 56, 57, 58])\n",
      "\n",
      "Batch index 211:\n",
      "Unsorted: tensor([37, 47, 58, 30, 11, 28, 63, 27, 38, 39, 55, 40, 54, 24, 18, 34, 59, 49,\n",
      "        12, 48, 19,  9,  7,  4, 10, 46, 15, 21, 51, 22,  1, 25, 23, 31, 62, 57,\n",
      "        53])\n",
      "Expected Sorted: tensor([ 1,  4,  7,  9, 10, 11, 12, 15, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30,\n",
      "        31, 34, 37, 38, 39, 40, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 62,\n",
      "        63])\n",
      "Predicted Sorted: tensor([ 1,  4,  7,  9, 10, 11, 12, 15, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30,\n",
      "        31, 30, 37, 38, 39, 40, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 62,\n",
      "        63])\n",
      "\n",
      "Batch index 255:\n",
      "Unsorted: tensor([ 8, 63,  6, 33, 30, 12, 14, 13, 26, 60,  9, 62,  2, 10,  4, 41, 56, 59,\n",
      "         0, 49, 42, 28, 46, 20, 51, 24, 11, 44, 23, 27, 36, 48, 61, 58, 55, 32,\n",
      "        31, 52, 47, 37, 19])\n",
      "Expected Sorted: tensor([ 0,  2,  4,  6,  8,  9, 10, 11, 12, 13, 14, 19, 20, 23, 24, 26, 27, 28,\n",
      "        30, 31, 32, 33, 36, 37, 41, 42, 44, 46, 47, 48, 49, 51, 52, 55, 56, 58,\n",
      "        59, 60, 61, 62, 63])\n",
      "Predicted Sorted: tensor([ 0,  2,  4,  6,  8,  9, 10, 11, 12, 13, 14, 19, 20,  2, 24, 26, 27, 28,\n",
      "        30, 31, 32, 33, 36, 37, 41, 42, 44, 46, 47, 48, 49, 51, 52, 55, 56, 58,\n",
      "        59, 60, 61, 62, 63])\n",
      "\n",
      "Batch index 258:\n",
      "Unsorted: tensor([14, 58, 57,  2, 42, 52, 11, 59, 13, 53,  3, 20, 21, 63, 26, 15, 49, 40,\n",
      "        45, 16, 23, 30, 54, 29,  6,  4,  9, 27, 17, 31,  8, 24, 48, 50, 41,  1,\n",
      "        25, 60, 18, 43, 28,  7, 34, 44,  5, 55, 39])\n",
      "Expected Sorted: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 18, 20, 21,\n",
      "        23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 39, 40, 41, 42, 43, 44, 45, 48,\n",
      "        49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 63])\n",
      "Predicted Sorted: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 18, 20, 21,\n",
      "        23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 39, 40, 41, 42, 43, 44, 45, 48,\n",
      "        49, 50, 52, 53, 54, 55, 57, 58,  6, 60, 63])\n",
      "\n",
      "Batch index 264:\n",
      "Unsorted: tensor([59, 53, 36, 20, 22, 39, 11, 45, 29, 16, 33, 27, 60, 10, 51, 56,  6, 61,\n",
      "        34,  8, 63, 49, 50, 40,  0, 19,  9, 47, 62, 31, 57, 48, 42, 12,  1, 44,\n",
      "         4, 46, 24])\n",
      "Expected Sorted: tensor([ 0,  1,  4,  6,  8,  9, 10, 11, 12, 16, 19, 20, 22, 24, 27, 29, 31, 33,\n",
      "        34, 36, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 59, 60,\n",
      "        61, 62, 63])\n",
      "Predicted Sorted: tensor([ 0,  1,  4,  6,  8,  9, 10, 11, 12, 16, 19, 20, 22, 24, 27, 12, 31, 33,\n",
      "        34, 36, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 59, 60,\n",
      "        61, 62, 63])\n",
      "\n",
      "Batch index 323:\n",
      "Unsorted: tensor([31, 16, 51,  0, 20, 55, 23, 25, 30, 18, 34, 50,  9, 15, 56, 44,  1, 26,\n",
      "        63, 62,  2, 38, 52, 60, 35, 19,  8, 37, 61, 28, 24, 17, 59, 21, 39, 14,\n",
      "        22, 54, 32, 33])\n",
      "Expected Sorted: tensor([ 0,  1,  2,  8,  9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
      "        28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 44, 50, 51, 52, 54, 55, 56, 59,\n",
      "        60, 61, 62, 63])\n",
      "Predicted Sorted: tensor([ 0,  1,  2,  8,  9, 14, 15, 16, 17, 18, 19, 20, 21, 22,  2, 24, 25, 26,\n",
      "        28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 44, 50, 51, 52, 54, 55, 56, 59,\n",
      "        60, 61, 62, 63])\n",
      "\n",
      "Batch index 368:\n",
      "Unsorted: tensor([38, 19, 27, 45, 33, 28, 35, 48, 25, 40, 58,  2, 62,  9,  0, 46, 26, 60,\n",
      "        37, 57, 41, 47, 56, 21, 14, 17, 50, 42, 31,  8,  5, 15, 59,  1,  7, 43,\n",
      "        61, 55, 20, 39, 30, 49, 11])\n",
      "Expected Sorted: tensor([ 0,  1,  2,  5,  7,  8,  9, 11, 14, 15, 17, 19, 20, 21, 25, 26, 27, 28,\n",
      "        30, 31, 33, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55,\n",
      "        56, 57, 58, 59, 60, 61, 62])\n",
      "Predicted Sorted: tensor([ 0,  1,  2,  5,  7,  8,  9, 11, 14, 15, 17, 19, 20, 21, 25, 26, 27, 28,\n",
      "        30, 31, 33, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 55,\n",
      "        56, 57, 58, 59, 60, 61,  0])\n",
      "\n",
      "Batch index 437:\n",
      "Unsorted: tensor([62, 63, 49, 11, 14, 42, 59, 48, 15, 36, 38, 50,  5, 40,  3, 39, 55, 47,\n",
      "        44, 43, 21, 10, 35,  0, 37, 12, 33,  9, 32])\n",
      "Expected Sorted: tensor([ 0,  3,  5,  9, 10, 11, 12, 14, 15, 21, 32, 33, 35, 36, 37, 38, 39, 40,\n",
      "        42, 43, 44, 47, 48, 49, 50, 55, 59, 62, 63])\n",
      "Predicted Sorted: tensor([ 0,  3,  5,  9, 10, 11, 12, 14, 15, 21, 32, 33, 35, 36, 37, 38, 39, 40,\n",
      "        42, 43, 44, 47, 14, 49, 50, 55, 59, 62, 63])\n",
      "\n",
      "Batch index 619:\n",
      "Unsorted: tensor([41, 61,  5,  9, 60, 14, 52, 33, 37, 53,  3, 57, 59, 42, 34, 27, 23, 48,\n",
      "        54, 24, 55, 45, 51,  8, 50, 44, 13,  7, 31, 26, 56, 22, 63, 17, 30, 49,\n",
      "        21, 10])\n",
      "Expected Sorted: tensor([ 3,  5,  7,  8,  9, 10, 13, 14, 17, 21, 22, 23, 24, 26, 27, 30, 31, 33,\n",
      "        34, 37, 41, 42, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60,\n",
      "        61, 63])\n",
      "Predicted Sorted: tensor([ 3,  5,  7,  8,  9, 10, 13, 14, 17, 21, 22, 23, 24, 26, 27, 30, 31, 33,\n",
      "        30, 37, 41, 42, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60,\n",
      "        61, 63])\n",
      "\n",
      "Batch index 709:\n",
      "Unsorted: tensor([35, 34, 44, 48, 15, 50, 25, 60, 38, 10, 14, 42, 47,  4, 39, 13, 54, 19,\n",
      "         9,  6, 18, 59, 62, 37, 23, 33, 17, 52, 32,  1])\n",
      "Expected Sorted: tensor([ 1,  4,  6,  9, 10, 13, 14, 15, 17, 18, 19, 23, 25, 32, 33, 34, 35, 37,\n",
      "        38, 39, 42, 44, 47, 48, 50, 52, 54, 59, 60, 62])\n",
      "Predicted Sorted: tensor([ 1,  4,  6,  9, 10, 13, 14, 15, 17, 18, 19, 23, 25, 32, 33, 34, 35, 37,\n",
      "        38, 39, 42, 44, 47, 14, 50, 52, 54, 59, 60, 62])\n",
      "\n",
      "Batch index 748:\n",
      "Unsorted: tensor([42, 45, 51, 28, 10, 49, 48, 52, 50, 57, 31, 58, 24, 15, 46, 18, 22, 39,\n",
      "        59, 36, 17, 55, 23, 43, 16, 53, 29,  0,  6,  3, 19,  7,  1, 20, 13,  9,\n",
      "         5, 41, 61, 11, 62, 25,  4])\n",
      "Expected Sorted: tensor([ 0,  1,  3,  4,  5,  6,  7,  9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22,\n",
      "        23, 24, 25, 28, 29, 31, 36, 39, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52,\n",
      "        53, 55, 57, 58, 59, 61, 62])\n",
      "Predicted Sorted: tensor([ 0,  1,  3,  4,  5,  6,  7,  9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22,\n",
      "        23, 24, 25, 28, 29, 31, 36, 39, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52,\n",
      "        53, 55, 57, 58, 59, 61,  0])\n",
      "\n",
      "Batch index 760:\n",
      "Unsorted: tensor([56,  5, 30, 40,  8, 29, 34,  0, 21, 28, 36,  2, 61, 60, 63, 54, 38, 52,\n",
      "        19, 12, 37, 53, 46, 62,  4,  3, 44, 33,  9, 11, 51, 31, 43, 32, 49, 55,\n",
      "        35, 48, 25, 24, 41, 14])\n",
      "Expected Sorted: tensor([ 0,  2,  3,  4,  5,  8,  9, 11, 12, 14, 19, 21, 24, 25, 28, 29, 30, 31,\n",
      "        32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 46, 48, 49, 51, 52, 53, 54,\n",
      "        55, 56, 60, 61, 62, 63])\n",
      "Predicted Sorted: tensor([ 0,  2,  3,  4,  5,  8,  9, 11, 12, 14, 19, 21, 24, 25, 28, 29, 30, 31,\n",
      "        32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 46, 14, 49, 51, 52, 53, 54,\n",
      "        55, 56, 60, 61, 62, 63])\n",
      "\n",
      "Batch index 811:\n",
      "Unsorted: tensor([37, 44, 11, 12, 52,  9, 19, 63, 35, 58, 36, 61, 48, 13, 10, 26, 47, 38,\n",
      "        14,  5, 41, 56,  7, 18, 62, 16,  1,  2, 28])\n",
      "Expected Sorted: tensor([ 1,  2,  5,  7,  9, 10, 11, 12, 13, 14, 16, 18, 19, 26, 28, 35, 36, 37,\n",
      "        38, 41, 44, 47, 48, 52, 56, 58, 61, 62, 63])\n",
      "Predicted Sorted: tensor([ 1,  2,  5,  7,  9, 10, 11, 12, 13, 14, 16, 18, 19, 26, 28, 35, 36, 37,\n",
      "        38, 41, 44, 47, 14, 52, 56, 58, 61, 62, 63])\n",
      "\n",
      "Batch index 960:\n",
      "Unsorted: tensor([58,  5, 17, 47, 54, 42, 60, 59,  7, 48, 55, 21, 62, 63, 43, 44, 46, 49,\n",
      "        36,  9, 50, 57, 27, 11, 41,  2, 22, 16,  8, 19, 12, 28, 53, 52, 40,  6,\n",
      "        30, 31, 15,  4, 35, 26,  3, 25, 39, 38, 61, 34])\n",
      "Expected Sorted: tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 15, 16, 17, 19, 21, 22, 25, 26,\n",
      "        27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49,\n",
      "        50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63])\n",
      "Predicted Sorted: tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 15, 16, 17, 19, 21, 22, 25, 26,\n",
      "        27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49,\n",
      "        50, 52, 53, 54, 55, 57, 58,  6, 60, 61, 62, 63])\n",
      "\n",
      "Batch index 981:\n",
      "Unsorted: tensor([33, 20, 29, 23, 35, 58, 48, 27, 10,  8, 37, 47, 57, 40, 22,  1,  7, 30,\n",
      "        41, 51, 31, 53, 34, 26, 38, 24, 60, 44, 25, 50, 12, 43,  5, 52, 42])\n",
      "Expected Sorted: tensor([ 1,  5,  7,  8, 10, 12, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34,\n",
      "        35, 37, 38, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 57, 58, 60])\n",
      "Predicted Sorted: tensor([ 1,  5,  7,  8, 10, 12, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 25,\n",
      "        35, 37, 38, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 57, 58, 60])\n",
      "\n",
      "\n",
      "Validating on test data:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     show_mispreds(model, val_data, val_data[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValidating on test data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m=:\u001b[39;00m\u001b[38;5;124m.3%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_acc \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[1;32mIn[19], line 99\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, val_data)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_model\u001b[39m(model: HookedTransformer, val_data: Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m---> 99\u001b[0m     val_tokens, val_lengths \u001b[38;5;241m=\u001b[39m val_data\n\u001b[0;32m    100\u001b[0m     val_logits \u001b[38;5;241m=\u001b[39m model(val_tokens\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[0;32m    101\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m loss_fn(val_logits, val_tokens\u001b[38;5;241m.\u001b[39mto(DEVICE), val_lengths\u001b[38;5;241m.\u001b[39mto(DEVICE))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def show_mispreds(model: HookedTransformer, data: Tuple[Tensor, Tensor], lengths: Tensor) -> None:\n",
    "    tokens, lengths = data\n",
    "    logits = model(tokens)\n",
    "    preds = logits.argmax(-1)  # Get the predictions by taking the argmax over the vocab dimension\n",
    "\n",
    "    for i in range(tokens.size(0)):\n",
    "        length = lengths[i].item()\n",
    "        sorted_start_pos = 1 + length + 1  # Position where sorted sequence starts\n",
    "\n",
    "        # Actual sorted tokens\n",
    "        actual_sorted = tokens[i, sorted_start_pos:sorted_start_pos+length]\n",
    "        \n",
    "        # Predicted sorted tokens\n",
    "        predicted_sorted = preds[i, sorted_start_pos:sorted_start_pos+length]\n",
    "        \n",
    "        # Calculate mask for padding values\n",
    "        mask = (actual_sorted != PADDING_VALUE)\n",
    "\n",
    "        # Check if there is any mismatch\n",
    "        if not (predicted_sorted == actual_sorted).all().item():\n",
    "            print(f\"Batch index {i}:\")\n",
    "            print(f\"Unsorted: {tokens[i, 1:length+1]}\")\n",
    "            print(f\"Expected Sorted: {actual_sorted[mask]}\")\n",
    "            print(f\"Predicted Sorted: {predicted_sorted[mask]}\\n\")\n",
    "\n",
    "# Assuming the rest of the code remains the same\n",
    "\n",
    "print(\"Validating on validation data:\")\n",
    "val_acc = validate_model(model, val_data)[0]\n",
    "print(f\"\\t{val_acc=:.3%}\\n\")\n",
    "if val_acc < 1:\n",
    "    show_mispreds(model, val_data, val_data[1])\n",
    "\n",
    "print(\"\\nValidating on test data:\")\n",
    "test_acc = validate_model(model, test_data)[0]\n",
    "print(f\"\\t{test_acc=:.3%}\\n\")\n",
    "if test_acc < 1:\n",
    "    show_mispreds(model, test_data, test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e6209-f57b-4f43-821a-ddd19523de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3a6af3d-98e0-4535-9877-2b43b0a686a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_acc)\n",
      "Cell \u001b[1;32mIn[19], line 99\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, val_data)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_model\u001b[39m(model: HookedTransformer, val_data: Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m---> 99\u001b[0m     val_tokens, val_lengths \u001b[38;5;241m=\u001b[39m val_data\n\u001b[0;32m    100\u001b[0m     val_logits \u001b[38;5;241m=\u001b[39m model(val_tokens\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[0;32m    101\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m loss_fn(val_logits, val_tokens\u001b[38;5;241m.\u001b[39mto(DEVICE), val_lengths\u001b[38;5;241m.\u001b[39mto(DEVICE))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "val_acc, val_loss = validate_model(model, test_data)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea009937-c0f3-42bc-933d-efaf4443682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(make_data_gen(batch_size=1000, dataset=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ca1338c-13d9-4bb5-80bd-ac54da5ca921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64, 50, 43, 38, 19,  5, 16, 57, 21,  1, 35, 41, 36,  4, 46,  3, 54, 29,\n",
       "         0, 40, 18, 30, 14, 17,  6, 58,  7, 48, 10,  8, 20, 56, 44, 65,  0,  1,\n",
       "         3,  4,  5,  6,  7,  8, 10, 14, 16, 17, 18, 19, 20, 21, 29, 30, 35, 36,\n",
       "        38, 40, 41, 43, 44, 46, 48, 50, 54, 56, 57, 58, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0][73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3342d8c-f81b-430f-9753-6f80a4f6b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982\n"
     ]
    }
   ],
   "source": [
    "test_data = next(make_data_gen(batch_size=1000, dataset=\"test\"))\n",
    "test_acc, test_loss = validate_model(model, test_data)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6bdb268-0d55-4088-9396-110b6562559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Length: 2 -> Accuracy: 100.00%\n",
      "List Length: 3 -> Accuracy: 100.00%\n",
      "List Length: 4 -> Accuracy: 100.00%\n",
      "List Length: 5 -> Accuracy: 100.00%\n",
      "List Length: 6 -> Accuracy: 100.00%\n",
      "List Length: 7 -> Accuracy: 100.00%\n",
      "List Length: 8 -> Accuracy: 100.00%\n",
      "List Length: 9 -> Accuracy: 100.00%\n",
      "List Length: 10 -> Accuracy: 100.00%\n",
      "List Length: 11 -> Accuracy: 100.00%\n",
      "List Length: 12 -> Accuracy: 100.00%\n",
      "List Length: 13 -> Accuracy: 100.00%\n",
      "List Length: 14 -> Accuracy: 100.00%\n",
      "List Length: 15 -> Accuracy: 100.00%\n",
      "List Length: 16 -> Accuracy: 100.00%\n",
      "List Length: 17 -> Accuracy: 100.00%\n",
      "List Length: 18 -> Accuracy: 100.00%\n",
      "List Length: 19 -> Accuracy: 100.00%\n",
      "List Length: 20 -> Accuracy: 100.00%\n",
      "List Length: 21 -> Accuracy: 100.00%\n",
      "List Length: 22 -> Accuracy: 100.00%\n",
      "List Length: 23 -> Accuracy: 100.00%\n",
      "List Length: 24 -> Accuracy: 100.00%\n",
      "List Length: 25 -> Accuracy: 100.00%\n",
      "List Length: 26 -> Accuracy: 100.00%\n",
      "List Length: 27 -> Accuracy: 100.00%\n",
      "List Length: 28 -> Accuracy: 100.00%\n",
      "List Length: 29 -> Accuracy: 100.00%\n",
      "List Length: 30 -> Accuracy: 99.78%\n",
      "List Length: 31 -> Accuracy: 99.85%\n",
      "List Length: 32 -> Accuracy: 100.00%\n",
      "List Length: 33 -> Accuracy: 99.86%\n",
      "List Length: 34 -> Accuracy: 99.83%\n",
      "List Length: 35 -> Accuracy: 99.90%\n",
      "List Length: 36 -> Accuracy: 100.00%\n",
      "List Length: 37 -> Accuracy: 100.00%\n",
      "List Length: 38 -> Accuracy: 100.00%\n",
      "List Length: 39 -> Accuracy: 100.00%\n",
      "List Length: 40 -> Accuracy: 99.92%\n",
      "List Length: 41 -> Accuracy: 99.56%\n",
      "List Length: 42 -> Accuracy: 100.00%\n",
      "List Length: 43 -> Accuracy: 99.44%\n",
      "List Length: 44 -> Accuracy: 100.00%\n",
      "List Length: 45 -> Accuracy: 100.00%\n",
      "List Length: 46 -> Accuracy: 100.00%\n",
      "List Length: 47 -> Accuracy: 100.00%\n",
      "List Length: 48 -> Accuracy: 99.85%\n",
      "List Length: 49 -> Accuracy: 99.92%\n",
      "List Length: 50 -> Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def acc_per_length(\n",
    "    model: HookedTransformer,\n",
    "    logits: Tensor,\n",
    "    tokens: Tensor,\n",
    "    lengths: Tensor,\n",
    "    padding_value: int = -1\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"Compute accuracy for each list length.\"\"\"\n",
    "    length_accs = {}\n",
    "    length_counts = {}\n",
    "\n",
    "    batch_size = tokens.size(0)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        length = lengths[i].item()\n",
    "        logits_sorted = logits[i, 1 + length + 1:1 + 2 * length + 1]\n",
    "        tokens_sorted = tokens[i, 1 + length + 1:1 + 2 * length + 1]\n",
    "\n",
    "        preds = logits_sorted.argmax(-1)\n",
    "        mask = (tokens_sorted != padding_value)\n",
    "        correct_tokens = (preds == tokens_sorted) * mask\n",
    "\n",
    "        if length not in length_accs:\n",
    "            length_accs[length] = 0\n",
    "            length_counts[length] = 0\n",
    "\n",
    "        length_accs[length] += correct_tokens.sum().item()\n",
    "        length_counts[length] += mask.sum().item()\n",
    "\n",
    "    for length in length_accs:\n",
    "        length_accs[length] /= length_counts[length]\n",
    "    \n",
    "    return length_accs\n",
    "\n",
    "# Assuming `model`, `test_data` are available\n",
    "test_tokens, test_lengths = test_data\n",
    "test_logits = model(test_tokens.to(DEVICE))\n",
    "length_accuracies = acc_per_length(model, test_logits, test_tokens.to(DEVICE), test_lengths)\n",
    "\n",
    "# Print length accuracies\n",
    "for length, acc in sorted(length_accuracies.items()):\n",
    "    print(f\"List Length: {length} -> Accuracy: {acc:.2%}\")\n",
    "\n",
    "# Plotting the effect of list length on accuracy\n",
    "def plot_length_accuracies(length_accuracies: Dict[int, float]):\n",
    "    lengths = sorted(length_accuracies.keys())\n",
    "    accuracies = [length_accuracies[length] for length in lengths]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(lengths, accuracies, marker='o')\n",
    "    plt.xlabel('List Length')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Effect of List Length on Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_length_accuracies(length_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59545fb5-90f4-4467-b1aa-7d66b5697945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Generator, Tuple\n",
    "\n",
    "def gather_length_stats(generator: Generator[Tuple[Tensor, Tensor], None, None], num_batches: int) -> Dict[int, int]:\n",
    "    length_counts = {}\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        _, lengths = next(generator)\n",
    "        for length in lengths:\n",
    "            length = length.item()\n",
    "            if length not in length_counts:\n",
    "                length_counts[length] = 0\n",
    "            length_counts[length] += 1\n",
    "\n",
    "    return length_counts\n",
    "\n",
    "# Analyzing train data\n",
    "train_gen = make_data_gen(batch_size=128, dataset=\"train\")\n",
    "train_length_stats = gather_length_stats(train_gen, num_batches=10)  # Adjust based on your requirement\n",
    "\n",
    "# Analyzing test data\n",
    "test_gen = make_data_gen(batch_size=1000, dataset=\"test\")\n",
    "test_length_stats = gather_length_stats(test_gen, num_batches=1)  # Adjust based on your requirement\n",
    "\n",
    "def plot_length_distribution(length_stats: Dict[int, int], title: str):\n",
    "    lengths = sorted(length_stats.keys())\n",
    "    counts = [length_stats[length] for length in lengths]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(lengths, counts)\n",
    "    plt.xlabel('List Length')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plotting train length distribution\n",
    "plot_length_distribution(train_length_stats, \"Train Data Length Distribution\")\n",
    "\n",
    "# Plotting test length distribution\n",
    "plot_length_distribution(test_length_stats, \"Test Data Length Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8aa751-e47d-4d26-9a31-0d401ea58d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_state_dict(\n",
    "    model: HookedTransformer,\n",
    "    filename: str | None = None\n",
    ") -> None:\n",
    "    if not os.path.isdir(\"C:/Users/DELL/Downloads/models\"):\n",
    "        os.mkdir(\"C:/Users/DELL/Downloads/models\")\n",
    "    if not filename:\n",
    "        timestamp = dt.now().isoformat(\"T\", \"minutes\").replace(\":\", \"-\")\n",
    "        filename = f\"model_state_dict_{timestamp}.pkl\"\n",
    "    with open(f\"C:/Users/DELL/Downloads/models/{filename}\", \"wb\") as f:\n",
    "        pickle.dump(model.state_dict(), f)\n",
    "\n",
    "save_model_state_dict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92630a0d-3d6b-4f18-847d-5fcaadcfbe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_state_dict_2024-07-31T21-57.pkl',\n",
       " 'model_state_dict_2024-07-31T21-59.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598db32-c916-437d-9c23-655974e914c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ea045-b6be-4d56-864c-87c143497691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c37f8b9-3410-4df1-9e40-1ccb97ea86f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "666799dd-37d6-448d-bdef-6ace5ef147d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: ['64', '11', '4', '59', '36', '38', '14', '53', '34', '1', '20', '9', '10', '35', '52', '8', '18', '3', '39', '27', '22', '24', '37', '2', '54', '32', '43', '55', '29', '58', '50', '57', '41', '65', '1', '2', '3', '4', '8', '9', '10', '11', '14', '18', '20', '22', '24', '27', '29', '32', '34', '35', '36', '37', '38', '39', '41', '43', '50', '52', '53', '54', '55', '57', '58', '59', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Predicted Sorted Tokens: [[1, 2, 3, 4, 8, 9, 10, 11, 14, 18, 20, 22, 24, 27, 29, 32, 34, 35, 36, 37, 38, 39, 41, 43, 50, 52, 53, 54, 55, 57, 58, 59]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Generator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import circuitsvis as cv\n",
    "\n",
    "# (Assuming other parts of your code are unchanged)\n",
    "\n",
    "# Get one input from test_data\n",
    "test_input, test_length = test_data\n",
    "test_input_single = test_input[3, :].unsqueeze(0)  # reshape to add batch dimension\n",
    "test_length_single = test_length[3].unsqueeze(0)  # length of the single test input\n",
    "max_sorted_length = test_length_single.item()  # Maximum length after sorting\n",
    "\n",
    "# Pass through model, get cache and predictions\n",
    "logits, cache_model = model.run_with_cache(test_input_single.to(DEVICE), remove_batch_dim=False)\n",
    "preds = logits[:, 1 + max_sorted_length + 1 : 1 + 2 * max_sorted_length + 1].argmax(-1)\n",
    "\n",
    "# Get attention pattern and plot it\n",
    "attention_pattern = cache_model[\"pattern\", 0, \"attn\"][0]  # Get attention pattern for layer 0 head 0\n",
    "\n",
    "# Convert tokens to their string representations\n",
    "def token_to_str(token_id):\n",
    "    if token_id == PADDING_VALUE:\n",
    "        return \"<PAD>\"\n",
    "   # elif token_id == START_TOKEN_ID:\n",
    "    #    return \"<START>\"\n",
    "    #elif token_id == MID_TOKEN_ID:\n",
    "     #   return \"<MID>\"\n",
    "    else:\n",
    "        return str(token_id.item())\n",
    "\n",
    "tokens_input = list(map(token_to_str, test_input_single[0]))\n",
    "\n",
    "print(\"Input Tokens:\", tokens_input)\n",
    "print(\"Predicted Sorted Tokens:\", preds.cpu().tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3b3409b-5c6e-4473-9a8b-6b03e42e0e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-2370cb3d-a3c9\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-2370cb3d-a3c9\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"64\", \"11\", \"4\", \"59\", \"36\", \"38\", \"14\", \"53\", \"34\", \"1\", \"20\", \"9\", \"10\", \"35\", \"52\", \"8\", \"18\", \"3\", \"39\", \"27\", \"22\", \"24\", \"37\", \"2\", \"54\", \"32\", \"43\", \"55\", \"29\", \"58\", \"50\", \"57\", \"41\", \"65\", \"1\", \"2\", \"3\", \"4\", \"8\", \"9\", \"10\", \"11\", \"14\", \"18\", \"20\", \"22\", \"24\", \"27\", \"29\", \"32\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"41\", \"43\", \"50\", \"52\", \"53\", \"54\", \"55\", \"57\", \"58\", \"59\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\", \"<PAD>\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06656325608491898, 0.9334366917610168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09202484786510468, 0.0199869517236948, 0.8879882097244263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16999980807304382, 0.018786665052175522, 0.00868409313261509, 0.802529513835907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05657205358147621, 0.003085724078118801, 0.027123386040329933, 0.017753606662154198, 0.8954651951789856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33392080664634705, 0.0070526208728551865, 0.025030730292201042, 0.004202393814921379, 0.00669830571860075, 0.6230950951576233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01327489037066698, 0.010804438032209873, 0.010682748630642891, 0.01007225550711155, 0.00776680838316679, 0.027226600795984268, 0.9201722741127014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12373939156532288, 0.00775509886443615, 0.054558057337999344, 0.03984709456562996, 0.0387391597032547, 0.004146717954427004, 0.005316659342497587, 0.7258977890014648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0218381155282259, 0.0028280355036258698, 0.002020333893597126, 0.005572366062551737, 0.007534771226346493, 0.0012314929626882076, 0.0016549857100471854, 0.011168432421982288, 0.9461515545845032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024742488749325275, 0.000981045188382268, 0.001133372774347663, 0.005935691762715578, 0.001878833631053567, 0.000724292011000216, 0.0030681134667247534, 0.0021637247409671545, 0.003789895446971059, 0.9778507351875305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005792337004095316, 0.03158222883939743, 0.0012218065094202757, 0.04192561283707619, 0.002631607698276639, 0.003360142931342125, 0.0027616096194833517, 0.0020966213196516037, 0.008100956678390503, 0.000904634187463671, 0.89962238073349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020189639180898666, 0.008498829789459705, 0.00792495347559452, 0.0027403635904192924, 0.0015467588091269135, 0.003918454982340336, 0.004180309362709522, 0.0027885623276233673, 0.0009075849666260183, 0.009699217975139618, 0.006516570691019297, 0.9310889840126038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014111875789240003, 0.034055400639772415, 0.002629358321428299, 0.005508621223270893, 0.0032159460242837667, 0.005747104063630104, 0.002963696839287877, 0.0015815701335668564, 0.005540075711905956, 0.0009533500415273011, 0.023013269528746605, 0.010550947859883308, 0.9028294086456299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07830677926540375, 0.021066928282380104, 0.02330169267952442, 0.030712787061929703, 0.05285040661692619, 0.0019028227543458343, 0.005697169341146946, 0.011544546112418175, 0.059631865471601486, 0.008184602484107018, 0.044464025646448135, 0.00691956328228116, 0.011751662939786911, 0.6436651349067688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021935520693659782, 0.009740249253809452, 0.007750562392175198, 0.059689171612262726, 0.021359283477067947, 0.024982012808322906, 0.05678847059607506, 0.012540140189230442, 0.0033855892252177, 0.014493744820356369, 0.0076959701254963875, 0.01685965806245804, 0.005000339820981026, 0.015312232077121735, 0.7224670648574829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00489126518368721, 0.0029833537992089987, 0.007672810927033424, 0.0013897448079660535, 0.0033297750633209944, 0.022631797939538956, 0.0010359425796195865, 0.005660617258399725, 0.016153564676642418, 0.0010984874097630382, 0.007100055459886789, 0.002709668129682541, 0.006990659050643444, 0.0014178587589412928, 0.0010960339568555355, 0.9138383269309998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018770311027765274, 0.0017038952792063355, 0.01237599179148674, 0.007949364371597767, 0.002956532873213291, 0.01771209016442299, 0.010898057371377945, 0.004186308477073908, 0.000588765658903867, 0.012551892548799515, 0.0020644532050937414, 0.010893408209085464, 0.0026117661036551, 0.0011033088667318225, 0.00916799996048212, 0.003139207838103175, 0.8813266158103943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.022294282913208008, 0.008545092307031155, 0.012510824017226696, 0.005527356639504433, 0.005122837610542774, 0.009443769231438637, 0.006538865622133017, 0.0028596746269613504, 0.003236308228224516, 0.03352690115571022, 0.002535043051466346, 0.01348274014890194, 0.019492018967866898, 0.0031115629244595766, 0.003763088956475258, 0.009905563667416573, 0.03667783364653587, 0.801426112651825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0038521517999470234, 0.0029330942779779434, 0.007949053309857845, 0.009448651224374771, 0.0077516622841358185, 0.0023752241395413876, 0.0029509160667657852, 0.0035716353449970484, 0.02978879027068615, 0.0010971429292112589, 0.011713550426065922, 0.0038181680720299482, 0.0022299604024738073, 0.027598518878221512, 0.0031238305382430553, 0.004266511648893356, 0.0016921904170885682, 0.002351860050112009, 0.8714872002601624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009795681107789278, 0.000853599573019892, 0.0067388033494353294, 0.0001848892861744389, 0.03479848429560661, 0.008832097053527832, 0.0033214944414794445, 0.010090675204992294, 0.00349428690969944, 0.020654426887631416, 0.00017884878616314381, 0.00322899897582829, 0.0033950202632695436, 0.0007885280647315085, 0.00075252924580127, 0.014373419806361198, 0.000908581365365535, 0.004582997877150774, 0.003389546414837241, 0.8784531950950623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09639768302440643, 0.0015689944848418236, 0.004844397772103548, 0.009668922051787376, 0.0012053054524585605, 0.0010233124485239387, 0.0009959586896002293, 0.0020112853962928057, 0.014800096862018108, 0.007092183455824852, 0.03508623316884041, 0.008939319290220737, 0.001904879929497838, 0.006567759905010462, 0.0035833469592034817, 0.0006436546100303531, 0.007654916495084763, 0.013004617765545845, 0.03735227882862091, 0.002586908405646682, 0.7430680394172668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03905458375811577, 0.00026637769769877195, 0.011931140907108784, 0.0011492305202409625, 0.0003101348702330142, 0.0036394556518644094, 0.0005183506291359663, 0.0078078280203044415, 0.00019974508904851973, 0.0013772405218333006, 0.0003391078789718449, 0.0009136292501352727, 0.0001288403436774388, 0.00038757576839998364, 0.0023397975601255894, 8.059693936957046e-05, 0.0012581964256241918, 0.0007520736544393003, 0.0009566989610902965, 0.0003064898191951215, 0.003927501849830151, 0.9223554730415344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056478116661310196, 0.0021693354938179255, 0.0007875491282902658, 0.010703852400183678, 0.0012405080487951636, 0.001879942137748003, 0.0015570054529234767, 0.005904938094317913, 0.009759552776813507, 0.0031867451034486294, 0.01500299945473671, 0.008880484849214554, 0.009378641843795776, 0.004918979946523905, 0.0006187415565364063, 0.0013186696451157331, 0.00770970294252038, 0.001406442723236978, 0.011234589852392673, 0.003522393060848117, 0.01792730577290058, 0.003942909184843302, 0.8204706311225891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09022463858127594, 0.0023919441737234592, 0.003122043563053012, 0.001177147263661027, 0.0031334797386080027, 0.059879910200834274, 0.015226494520902634, 0.0026235426776111126, 0.0016030652914196253, 0.007430234923958778, 0.0012962210457772017, 0.006881471257656813, 0.014936662279069424, 0.005069251637905836, 0.0051438091322779655, 0.0057759652845561504, 0.004970110487192869, 0.006956680677831173, 0.0043661147356033325, 0.007249400485306978, 0.005164337810128927, 0.0017838277854025364, 0.0013563245302066207, 0.742237389087677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0187950748950243, 0.00344721507281065, 0.01598859392106533, 0.006963057909160852, 0.0081565510481596, 0.0033951709046959877, 0.002833205508068204, 0.011087868362665176, 0.001444281660951674, 0.0047833556309342384, 0.0019994471222162247, 0.0025669261813163757, 0.0017083173152059317, 0.005986012984067202, 0.003061258466914296, 0.008382878266274929, 0.019020594656467438, 0.005153405014425516, 0.0036212755367159843, 0.017771463841199875, 0.0019667213782668114, 0.019319437444210052, 0.008130994625389576, 0.00892626028507948, 0.8154906034469604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17410846054553986, 0.0021339417435228825, 0.004928532522171736, 0.01163669303059578, 0.0024719280190765858, 0.009873582050204277, 0.001615122309885919, 0.028946740552783012, 0.012307444587349892, 0.0020150106865912676, 0.011191862635314465, 0.005737998057156801, 0.0022637329529970884, 0.008614235557615757, 0.0070569394156336784, 0.00682020140811801, 0.011248396709561348, 0.0003927830548491329, 0.004653693176805973, 0.0013658086536452174, 0.008797949180006981, 0.012680868618190289, 0.022641396149992943, 0.005237579811364412, 0.018033893778920174, 0.623225212097168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002832704456523061, 0.0009457014966756105, 0.00315336836501956, 0.0011128400219604373, 0.0026709611993283033, 0.0017287802184000611, 0.002770383143797517, 0.0051444959826767445, 0.0007117480272427201, 0.005166382063180208, 0.0005663569318130612, 0.00706248264759779, 0.003211231203749776, 0.0007366528734564781, 0.0021294921170920134, 0.0011314884759485722, 0.005470686126500368, 0.006206047255545855, 0.0009034426766447723, 0.023590950295329094, 0.003132214304059744, 0.002789634745568037, 0.0012735401978716254, 0.0036523311864584684, 0.0024086853954941034, 0.0030137826688587666, 0.9064836502075195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06152357533574104, 0.006313895341008902, 0.009110435843467712, 0.0021607447415590286, 0.0024922180455178022, 0.001868108636699617, 0.0010585917625576258, 0.004578710999339819, 0.03454192355275154, 0.012713664211332798, 0.003704286180436611, 0.00830359198153019, 0.0034156430047005415, 0.017952537164092064, 0.0016453629359602928, 0.0020390767604112625, 0.0016460141632705927, 0.013022596947848797, 0.009516915306448936, 0.01179885771125555, 0.015977958217263222, 0.00734193017706275, 0.01899808645248413, 0.010737323202192783, 0.017020657658576965, 0.005143429152667522, 0.00818609818816185, 0.7071878910064697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24869735538959503, 0.0029485037084668875, 0.003476738464087248, 0.014464282430708408, 0.003979885950684547, 0.017526527866721153, 0.0010575484484434128, 0.02422722615301609, 0.013050991110503674, 0.0016811934765428305, 0.005953270476311445, 0.006551193073391914, 0.004022013861685991, 0.006268131546676159, 0.002370049012824893, 0.010937506332993507, 0.0027770427986979485, 0.0021989322267472744, 0.004911795258522034, 0.006992892827838659, 0.014626644551753998, 0.01104535162448883, 0.004048038274049759, 0.015592200681567192, 0.014558227732777596, 0.06943267583847046, 0.03801955282688141, 0.02202482335269451, 0.4265594482421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10202676057815552, 0.0009904245380312204, 0.00320174777880311, 0.0014719626633450389, 0.010601730085909367, 0.006331490818411112, 0.003720042295753956, 0.052808161824941635, 0.005553386639803648, 0.03431834653019905, 0.0026110801845788956, 0.005206685047596693, 0.0017470390303060412, 0.005845054984092712, 0.010004308074712753, 0.0013873156858608127, 0.0012661815853789449, 0.0010780268348753452, 0.012090807780623436, 0.03029167652130127, 0.009997707791626453, 0.02153160609304905, 0.061306942254304886, 0.007670897990465164, 0.007537325378507376, 0.0038986599538475275, 0.010034913197159767, 0.023572176694869995, 0.003264958504587412, 0.5586325526237488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046925418078899384, 0.0024011963978409767, 0.0031836056150496006, 0.003808647394180298, 0.0002630893141031265, 0.002960733138024807, 0.0006950977840460837, 0.0011507065501064062, 0.0026225449983030558, 0.0012598785106092691, 0.013416824862360954, 0.007014065980911255, 0.003905781079083681, 0.0018859028350561857, 0.0007905379752628505, 0.0032044847030192614, 0.014608151279389858, 0.025860628113150597, 0.001220458303578198, 0.0005358069320209324, 0.022511111572384834, 0.008870829828083515, 0.0020648264326155186, 0.015002641826868057, 0.017276598140597343, 0.010493087582290173, 0.0030924156308174133, 0.017169637605547905, 0.007629497908055782, 0.0007267053006216884, 0.7574490904808044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10520811378955841, 0.002511414932087064, 0.008068304508924484, 0.005266418680548668, 0.0010802475735545158, 0.0031895656138658524, 0.012913627550005913, 0.006309828720986843, 0.001279674470424652, 0.004924756474792957, 0.007099031470716, 0.0005802653613500297, 0.0031988262198865414, 0.002391564194113016, 0.000771870487369597, 0.0006158438045531511, 0.02002042531967163, 0.005659344606101513, 0.002961263293400407, 0.0034092983696609735, 0.019168803468346596, 0.016230713576078415, 0.006376686505973339, 0.006811120081692934, 0.01036626286804676, 0.007581603713333607, 0.0076667750254273415, 0.0038496775086969137, 0.0028344569727778435, 0.005943965632468462, 0.026171676814556122, 0.6895384788513184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013603896833956242, 0.0002780788345262408, 0.001692150835879147, 0.00025503619690425694, 0.00043705219286493957, 0.0008068055030889809, 0.003248529974371195, 0.0005043806158937514, 0.006682133302092552, 0.003144297981634736, 0.0008750727865844965, 0.018133491277694702, 0.0012758129741996527, 0.0006827068864367902, 0.00022879902098793536, 0.0010466664098203182, 0.006619689054787159, 0.0013519491767510772, 0.010072607547044754, 0.004393940791487694, 0.008527031168341637, 0.005608758423477411, 0.004046544432640076, 0.011677048169076443, 0.004903653170913458, 0.0020847273990511894, 0.0006029977812431753, 0.010955516248941422, 0.0029443632811307907, 0.0009525399655103683, 0.00214897352270782, 0.0011451805476099253, 0.8690694570541382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03728009760379791, 0.03132956847548485, 0.03455885127186775, 0.0069345892407000065, 0.007379903923720121, 0.004781409166753292, 0.0707523375749588, 0.0037805470637977123, 0.01743249222636223, 0.013586694374680519, 0.009512183256447315, 0.009896941483020782, 0.008888171054422855, 0.03513678163290024, 0.029943760484457016, 0.008335334248840809, 0.013653740286827087, 0.005706049967557192, 0.04871547222137451, 0.0033858465030789375, 0.0063653429970145226, 0.01537339948117733, 0.00814575795084238, 0.006994713097810745, 0.010362551547586918, 0.03969908505678177, 0.0009588840766809881, 0.0073369634337723255, 0.006810412276536226, 0.006023996975272894, 0.002505661454051733, 0.02404116839170456, 0.051018211990594864, 0.41337308287620544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003130468772724271, 0.005155627615749836, 0.004827931057661772, 0.017986051738262177, 0.004301442299038172, 0.001202562591060996, 0.01285909116268158, 0.009816322475671768, 0.004287106450647116, 0.22521205246448517, 0.0062010157853364944, 0.0027290675789117813, 0.002523427363485098, 0.0091015649959445, 0.010292593389749527, 0.002105651656165719, 0.0015434098895639181, 0.0036072491202503443, 0.02954869531095028, 0.00901133194565773, 0.00677060429006815, 0.014208490028977394, 0.014745309948921204, 0.006231207866221666, 0.016755981370806694, 0.0017522739944979548, 0.004866395145654678, 0.011759301647543907, 0.0023569734767079353, 0.0197621937841177, 0.0008523852447979152, 0.006226470693945885, 0.008233046159148216, 0.014612119644880295, 0.5054246187210083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03736967220902443, 0.0033057781402021646, 0.002756259171292186, 0.002035403624176979, 0.006628008093684912, 0.018930181860923767, 0.004001985304057598, 0.004857288673520088, 0.001364395720884204, 0.00786612555384636, 0.007251322269439697, 0.002444593235850334, 0.011803864501416683, 0.009184959344565868, 0.008496967144310474, 0.0028587402775883675, 0.0039016089867800474, 0.0021058223210275173, 0.008173074573278427, 0.002805328695103526, 0.007001145742833614, 0.003465093206614256, 0.0011228015646338463, 0.10925842076539993, 0.0033626514486968517, 0.0060144104063510895, 0.0013960589421913028, 0.003353453939780593, 0.0007508898270316422, 0.011256132274866104, 0.010202396661043167, 0.004026591777801514, 0.002073509618639946, 0.0055808634497225285, 0.009316726587712765, 0.6736774444580078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008074290119111538, 0.0030457668472081423, 0.00524627510458231, 0.0020359084010124207, 0.0013217420782893896, 0.0017116573872044683, 0.004402142483741045, 0.0017662321915850043, 0.0005098360707052052, 0.00345805031247437, 0.0015196322929114103, 0.05812884494662285, 0.005540005397051573, 0.0006736957584507763, 0.0026975523214787245, 0.0012288173893466592, 0.022924251854419708, 0.05125271901488304, 0.018458396196365356, 0.008823302574455738, 0.0024785902351140976, 0.009878034703433514, 0.0010024959919974208, 0.0069594839587807655, 0.005260834936052561, 0.000319930084515363, 0.022199999541044235, 0.004215542692691088, 0.003869901178404689, 0.0023272556718438864, 0.009774970822036266, 0.005142867565155029, 0.06433749198913574, 0.0054137515835464, 0.009030344896018505, 0.0016242129495367408, 0.6433451771736145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016657114028930664, 0.002034097444266081, 0.04825032502412796, 0.0007456053281202912, 0.006679635029286146, 0.004207800142467022, 0.004282388370484114, 0.003899651812389493, 0.0008164944010786712, 0.0021966220811009407, 0.001109884469769895, 0.0012639336055144668, 0.0007147755823098123, 0.0029405925888568163, 0.007143987808376551, 0.0019548037089407444, 0.0005431242170743644, 0.00038245299947448075, 0.004832306411117315, 0.002236057771369815, 0.001212526112794876, 0.02010231837630272, 0.0002876330690924078, 0.0004234390507917851, 0.00046108293463476, 0.004746792372316122, 0.004061765503138304, 0.0008123701554723084, 0.0018340760143473744, 0.0004587605071719736, 0.0003180909261573106, 0.0065437923185527325, 0.000702470017131418, 0.0019606866408139467, 0.002718148985877633, 0.0027696709148585796, 0.001107553020119667, 0.8365871906280518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010976720601320267, 0.0009738728986121714, 0.009947016835212708, 0.0005019105155952275, 0.002156811533495784, 0.006748989690095186, 0.002269066171720624, 0.003375041764229536, 0.01215263083577156, 0.0008921470725908875, 0.003532974747940898, 0.0019511498976498842, 0.0029714154079556465, 0.001766784000210464, 0.0006944056949578226, 0.07017922401428223, 0.0027974932454526424, 0.002646469511091709, 0.0041235764510929585, 0.004731548950076103, 0.006522165611386299, 0.0021718842908740044, 0.0005704474751837552, 0.016554860398173332, 0.0036516403779387474, 0.018191000446677208, 0.0012626912211999297, 0.006653579417616129, 0.014462186023592949, 0.0015315561322495341, 0.016265856102108955, 0.012566115707159042, 0.023622259497642517, 0.01094477716833353, 0.00019790201622527093, 0.00895832758396864, 0.0006602348294109106, 0.0043250578455626965, 0.7054981589317322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009174115024507046, 0.0052145193330943584, 0.015521826222538948, 0.0006403779843822122, 0.0007480296771973372, 0.001918311696499586, 0.002226117765530944, 0.0008026942959986627, 0.00010074631427414715, 0.0014394056051969528, 0.00155031424947083, 0.12313512712717056, 0.0020761447958648205, 0.0012520772870630026, 0.005172227509319782, 0.0009882851736620069, 0.004843708593398333, 0.0024159210734069347, 0.001135841477662325, 0.001318215043283999, 0.0013765713665634394, 0.013565583154559135, 0.003207413712516427, 0.0023998343385756016, 0.002982477657496929, 0.001679247710853815, 0.006003866903483868, 0.0020624175667762756, 0.0005913514760322869, 0.0022748829796910286, 0.004870379809290171, 0.0010509516578167677, 0.003154951147735119, 0.00038091070018708706, 0.0032916474156081676, 0.0007102933595888317, 0.013599598780274391, 0.011848569847643375, 0.0008871667669154704, 0.7423879504203796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0017234969418495893, 0.012978920713067055, 0.002537471242249012, 0.008989350870251656, 0.004912394564598799, 0.0012754328781738877, 0.0036714200396090746, 0.0018544665072113276, 0.0017570616910234094, 0.002137100324034691, 0.00401684083044529, 0.006971238646656275, 0.13395200669765472, 0.007225705776363611, 0.0015808987664058805, 0.006833123974502087, 0.005957373883575201, 0.004230191931128502, 0.0066440170630812645, 0.003804595675319433, 0.0019148277351632714, 0.0007579080993309617, 0.004684635438024998, 0.0139769883826375, 0.0050462656654417515, 0.004741357173770666, 0.0019168192520737648, 0.0018454116070643067, 0.00519289867952466, 0.0010826941579580307, 0.003152137389406562, 0.0007771039381623268, 0.006515059620141983, 0.01464762818068266, 0.019443698227405548, 0.007292402442544699, 0.005862083286046982, 0.00202013342641294, 0.004234359133988619, 0.006602467969059944, 0.6652399301528931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013116732239723206, 0.0996432900428772, 0.010737087577581406, 0.01316372212022543, 0.004357876721769571, 0.00583578972145915, 0.006247775163501501, 0.0024995808489620686, 0.002038045786321163, 0.0007659538532607257, 0.012679765932261944, 0.017383314669132233, 0.05129847675561905, 0.015967000275850296, 0.0051576183177530766, 0.005054230336099863, 0.037829842418432236, 0.015325312502682209, 0.0037771565839648247, 0.004875073675066233, 0.005150722339749336, 0.0020018713548779488, 0.012769563123583794, 0.0044214618392288685, 0.01599005237221718, 0.006741535384207964, 0.0062654875218868256, 0.017961356788873672, 0.008842830546200275, 0.0035453843884170055, 0.03169463202357292, 0.010455800220370293, 0.0013763168826699257, 0.003999910783022642, 0.0032507728319615126, 0.0029220746364444494, 0.030574627220630646, 0.00871820654720068, 0.0011909257154911757, 0.020322872325778008, 0.016389766708016396, 0.45766016840934753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0037096950691193342, 0.001682908390648663, 0.004284693393856287, 0.00687466561794281, 0.0022825298365205526, 0.014916078187525272, 0.06564626842737198, 0.0005024459096603096, 0.0004849929246120155, 0.0017528139287605882, 0.0002937683602795005, 0.0010919023770838976, 0.0006155177252367139, 0.0026252998504787683, 0.004785704426467419, 0.0004708560009021312, 0.018700432032346725, 0.000433915585745126, 0.001629707869142294, 0.001738757244311273, 0.0011329512344673276, 0.0027696886099874973, 0.0012059155851602554, 0.0023205592297017574, 0.0019101311918348074, 0.0134197399020195, 0.02630545385181904, 0.0026512981858104467, 0.004315630532801151, 0.0006401656428351998, 0.0003055727283935994, 0.003346615470945835, 0.005451580975204706, 0.019339701160788536, 0.004097335506230593, 0.0011765098897740245, 0.0032131201587617397, 0.0066513423807919025, 0.001171522424556315, 0.005897184368222952, 0.003504563355818391, 0.009864714927971363, 0.7447857856750488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006723124533891678, 0.0006026739138178527, 0.004699828568845987, 0.0031983451917767525, 0.0022560185752809048, 0.0025445136707276106, 0.003937625791877508, 0.0023724748753011227, 0.0006289836019277573, 0.0022657839581370354, 0.0008435674826614559, 0.0030350724700838327, 0.0011673950357362628, 0.0014815515605732799, 0.005640759598463774, 0.0022607333958148956, 0.18235458433628082, 0.002091158414259553, 0.0009154712315648794, 0.0034265785943716764, 0.00195904728025198, 0.0024775047786533833, 0.0028507611714303493, 0.007186993956565857, 0.05965588986873627, 0.012429584749042988, 0.002195758977904916, 0.00986046064645052, 0.0023428723216056824, 0.0027799750678241253, 0.012819061987102032, 0.002104161772876978, 0.007654799148440361, 0.004328557755798101, 0.00241995882242918, 0.008643664419651031, 0.004976305644959211, 0.0025943247601389885, 0.002999173477292061, 0.01015295647084713, 0.005446003284305334, 0.005411492194980383, 0.016144217923283577, 0.578120231628418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027244096621870995, 0.01765681430697441, 0.0031817741692066193, 0.030783601105213165, 0.010836253874003887, 0.003787720575928688, 0.0167130995541811, 0.002907467307522893, 0.012875352054834366, 0.007805405184626579, 0.06812653690576553, 0.010955207981169224, 0.00880790501832962, 0.03635916858911514, 0.0622270405292511, 0.001156394835561514, 0.0068485974334180355, 0.005356281995773315, 0.010602129623293877, 0.0005930031184107065, 0.02457231655716896, 0.01022670604288578, 0.003661038354039192, 0.006537024397403002, 0.0034148104023188353, 0.007412753067910671, 0.0049018245190382, 0.007934882305562496, 0.004464396275579929, 0.00222872756421566, 0.018200354650616646, 0.004042825195938349, 0.025568420067429543, 0.0046927365474402905, 0.01703561469912529, 0.020451858639717102, 0.01088071707636118, 0.012033683247864246, 0.003965573385357857, 0.03308258205652237, 0.022652089595794678, 0.010143888182938099, 0.009329146705567837, 0.006578516680747271, 0.38116368651390076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030857697129249573, 0.0009338505333289504, 0.0022974975872784853, 0.00346647878177464, 0.0008080750121735036, 0.0005599173600785434, 0.00037174622411839664, 0.0010321370791643858, 0.009602335281670094, 0.0014717866433784366, 0.022793076932430267, 0.002889295807108283, 0.002305916976183653, 0.004150080494582653, 0.0016950583085417747, 0.0005013085319660604, 0.00302964448928833, 0.0048963711597025394, 0.021356968209147453, 0.0006131219561211765, 0.1999092698097229, 0.020478423684835434, 0.010449026711285114, 0.000620288890786469, 0.001683207112364471, 0.001554529881104827, 0.0011434287298470736, 0.009265298023819923, 0.0014170767972245812, 0.0020428101997822523, 0.005026057828217745, 0.030894916504621506, 0.005263058468699455, 0.001762803760357201, 0.004036060068756342, 0.0016831991961225867, 0.009007256478071213, 0.01230187714099884, 0.0028752400539815426, 0.003379714209586382, 0.00042550836224108934, 0.001884598401375115, 0.001071497448720038, 0.002342405030503869, 0.010649718344211578, 0.5432003736495972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09807871282100677, 0.00033446718589402735, 0.005618763621896505, 0.0007767400238662958, 0.000961298355832696, 0.013874528929591179, 0.0011141678551211953, 0.004807658493518829, 0.0007843595230951905, 0.015615694224834442, 0.00023463113757316023, 0.0012193032307550311, 0.00021367217414081097, 0.0004230769700370729, 0.0031405785121023655, 0.0004197130911052227, 0.0013073893496766686, 0.006165322382003069, 0.0007470381096936762, 0.0015537927392870188, 0.00428576348349452, 0.19618605077266693, 0.000347749562934041, 0.003541522193700075, 0.0008239159942604601, 0.0012707612477242947, 0.002543003996834159, 0.0012790923938155174, 0.0013180430978536606, 0.007374654058367014, 0.0008599225548096001, 0.02384330704808235, 0.000882575346622616, 0.0007972274906933308, 0.003189843613654375, 0.013500377535820007, 0.0019296753453090787, 0.01943722553551197, 0.0008198964642360806, 0.0014701924519613385, 0.0005268407403491437, 0.00023115107615012676, 0.0012678585480898619, 0.00031576695619150996, 0.0012989675160497427, 0.012599709443747997, 0.5406680107116699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004566892166621983, 0.00497616408392787, 0.0018649478442966938, 0.000870517164003104, 0.01211755070835352, 0.0025182547979056835, 0.0010907152900472283, 0.003955534193664789, 0.011283500120043755, 0.003566964529454708, 0.0016862995689734817, 0.005977740976959467, 0.02723078802227974, 0.0011176766129210591, 0.0006570964469574392, 0.03803475201129913, 0.0012862783623859286, 0.009372478350996971, 0.0067254784516990185, 0.08274593204259872, 0.003915945068001747, 0.0008911502081900835, 0.004298417828977108, 0.0016838425071910024, 0.00089003931498155, 0.0004989090957678854, 0.003709556767717004, 0.0031366681214421988, 0.0061956122517585754, 0.005805213935673237, 0.0006640319479629397, 0.0021776382345706224, 0.00126603280659765, 0.00539169367402792, 0.0029788140673190355, 0.00142459396738559, 0.004426132421940565, 0.0019248477183282375, 0.0045987507328391075, 0.0007169425371102989, 0.005223636049777269, 0.003973235376179218, 0.0008714433060958982, 0.0015304898843169212, 0.00023958909150678664, 0.004819704685360193, 0.0030897660180926323, 0.7061219811439514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0710793137550354, 0.0018636486493051052, 0.001414273981936276, 0.009784732945263386, 0.002547354204580188, 0.0077041201293468475, 0.0014553447254002094, 0.008398356847465038, 0.004019821062684059, 0.0004123639373574406, 0.004523771815001965, 0.009887504391372204, 0.003961947746574879, 0.0026557715609669685, 0.005662442650645971, 0.007393920328468084, 0.00214551598764956, 0.0009285177802667022, 0.0036124656908214092, 0.001921345479786396, 0.006706119515001774, 0.0024291847366839647, 0.0013608685694634914, 0.007346472702920437, 0.00568343373015523, 0.025470102205872536, 0.014076597057282925, 0.004070157650858164, 0.12096062302589417, 0.0008130450733006, 0.010933802463114262, 0.001208959729410708, 0.009340032003819942, 0.0037949152756482363, 0.0008292050915770233, 0.0033291862346231937, 0.0025685837026685476, 0.0029022200033068657, 0.012073193676769733, 0.006395802367478609, 0.012510573491454124, 0.011696131899952888, 0.012482802383601665, 0.006217096000909805, 0.006028186995536089, 0.003334764391183853, 0.0020669621881097555, 0.0034841790329664946, 0.5485143065452576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10493128001689911, 0.005099484696984291, 0.0015754700871184468, 0.004344204440712929, 0.002485492965206504, 0.020524540916085243, 0.006690508686006069, 0.011512109078466892, 0.016357190907001495, 0.0017203671159222722, 0.006976014468818903, 0.004000332206487656, 0.007685034070163965, 0.0073633091524243355, 0.008139870129525661, 0.009530294686555862, 0.011190737597644329, 0.0008395157638005912, 0.0025495151057839394, 0.0013585073174908757, 0.0051975795067846775, 0.0031959544867277145, 0.00733265420421958, 0.032493360340595245, 0.01617072895169258, 0.13490884006023407, 0.0009798977989703417, 0.006769915111362934, 0.020247777923941612, 0.010106924921274185, 0.009436603635549545, 0.005641417112201452, 0.008692189119756222, 0.026827828958630562, 0.0012474707327783108, 0.04982718080282211, 0.0004451865970622748, 0.0012564433272928, 0.020157018676400185, 0.002266779076308012, 0.031118333339691162, 0.007025244180113077, 0.0057403314858675, 0.014068232849240303, 0.0052577657625079155, 0.0036228501703590155, 0.005235163029283285, 0.0017852508462965488, 0.02765330858528614, 0.30041804909706116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00234063807874918, 0.024171695113182068, 0.0047768279910087585, 0.03704660013318062, 0.009215922094881535, 0.0033677024766802788, 0.007324893958866596, 0.04542921483516693, 0.2754029631614685, 0.004230442922562361, 0.04120974987745285, 0.0038442127406597137, 0.009827795438468456, 0.01408358197659254, 0.00405974593013525, 0.06422041356563568, 0.003508341498672962, 0.00282239424996078, 0.0065780747681856155, 0.0036225675139576197, 0.008014257065951824, 0.003586598439142108, 0.03528051823377609, 0.0007162410183809698, 0.0037653655745089054, 0.04475384205579758, 0.0033655257429927588, 0.004539637826383114, 0.005055309273302555, 0.004320990294218063, 0.0072501120157539845, 0.01053741853684187, 0.001704312628135085, 0.025990044698119164, 0.0028015265706926584, 0.0036523554008454084, 0.0014655191916972399, 0.008504676632583141, 0.012613216415047646, 0.0008324264199472964, 0.0015043863095343113, 0.008519221097230911, 0.0028984008822590113, 0.006409215275198221, 0.003001657547429204, 0.009401822462677956, 0.0023823741357773542, 0.015611115843057632, 0.004788550082594156, 0.024755235761404037, 0.16489435732364655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05071578919887543, 0.007656538859009743, 0.010257474146783352, 0.018116815015673637, 0.020730940625071526, 0.002508466597646475, 0.0071384962648153305, 0.0019619546364992857, 0.009531865827739239, 0.010430436581373215, 0.023051640018820763, 0.002428054576739669, 0.005571392830461264, 0.19138404726982117, 0.015235583297908306, 0.0016650677425786853, 0.0072898343205451965, 0.004262852016836405, 0.032801926136016846, 0.004385754931718111, 0.02885817363858223, 0.0026280495803803205, 0.01118513010442257, 0.002430935623124242, 0.004176973830908537, 0.013994730077683926, 0.009660554118454456, 0.021216722205281258, 0.004801093600690365, 0.0035918508656322956, 0.005127628333866596, 0.025176135823130608, 0.0033038188703358173, 0.011242550797760487, 0.013699849136173725, 0.01058918982744217, 0.007735916879028082, 0.07243560999631882, 0.003619396360591054, 0.007368394639343023, 0.004729628562927246, 0.011310098692774773, 0.02906009554862976, 0.009411434642970562, 0.031182700768113136, 0.028409840539097786, 0.003788330825045705, 0.0061601996421813965, 0.004774944391101599, 0.00327171478420496, 0.005008515901863575, 0.17292481660842896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0360754132270813, 0.0011688449885696173, 0.016807444393634796, 0.00939425453543663, 0.0628463551402092, 0.0004698289558291435, 0.0036724840756505728, 0.035962436348199844, 0.07621730864048004, 0.003012659028172493, 0.0017286506481468678, 0.002156831556931138, 0.0011192894307896495, 0.07851004600524902, 0.005733226425945759, 0.006092629861086607, 0.0014030642341822386, 0.0008205472840927541, 0.022915484383702278, 0.015264824032783508, 0.0037996673490852118, 0.0058610886335372925, 0.014016480185091496, 0.0007303010788746178, 0.009447669610381126, 0.034079670906066895, 0.012642680667340755, 0.008672128431499004, 0.006544250994920731, 0.0040333750657737255, 0.0030832712072879076, 0.007687446661293507, 0.011417693458497524, 0.02085806056857109, 0.0020468560978770256, 0.0026243505999445915, 0.002485005185008049, 0.03156903758645058, 0.01627238094806671, 0.0024719543289393187, 0.0017060827231034636, 0.0016385276103392243, 0.018976859748363495, 0.0037085593212395906, 0.004279369488358498, 0.0029436552431434393, 0.0033932840451598167, 0.013485347852110863, 0.0045488313771784306, 0.004359292797744274, 0.013869944028556347, 0.03519880399107933, 0.31017646193504333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15654371678829193, 0.004113620147109032, 0.0013953446177765727, 0.010952658951282501, 0.0016112832818180323, 0.006573889404535294, 0.005898299161344767, 0.004374352283775806, 0.008502386510372162, 0.006716663017868996, 0.018117224797606468, 0.01147596724331379, 0.0237639918923378, 0.005049210041761398, 0.0013738913694396615, 0.0019577632192522287, 0.021913308650255203, 0.005229568108916283, 0.012722298502922058, 0.004551970865577459, 0.019159039482474327, 0.005467582959681749, 0.10665233433246613, 0.0040293424390256405, 0.005314641632139683, 0.024754401296377182, 0.01715276949107647, 0.014921344816684723, 0.023592311888933182, 0.014947245828807354, 0.00457818154245615, 0.017213109880685806, 0.01716483384370804, 0.014538520947098732, 0.01606815494596958, 0.003884222125634551, 0.03938891366124153, 0.0016229785978794098, 0.006043407134711742, 0.008235082030296326, 0.015527604147791862, 0.011153154075145721, 0.022265654057264328, 0.014801619574427605, 0.0065177264623343945, 0.026491863653063774, 0.0067946165800094604, 0.012517597526311874, 0.015526005066931248, 0.009547238238155842, 0.013533489778637886, 0.018070125952363014, 0.0038210691418498755, 0.14586639404296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09129957854747772, 0.010435412637889385, 0.011149474419653416, 0.00575686153024435, 0.007454711012542248, 0.0523565299808979, 0.01899728924036026, 0.019753005355596542, 0.0028535104356706142, 0.010611250065267086, 0.00883463304489851, 0.04056091979146004, 0.009276638738811016, 0.0025547570548951626, 0.014621593058109283, 0.024376478046178818, 0.029293738305568695, 0.006761019118130207, 0.003751448355615139, 0.017074204981327057, 0.008313527330756187, 0.011273471638560295, 0.016897622495889664, 0.016904450953006744, 0.013763575814664364, 0.02042975462973118, 0.005748314782977104, 0.006303321570158005, 0.02115589939057827, 0.0456332229077816, 0.008972667157649994, 0.010040183551609516, 0.007798871025443077, 0.005665098782628775, 0.012689494527876377, 0.01132580079138279, 0.01191222108900547, 0.009817644022405148, 0.01451092679053545, 0.02791697531938553, 0.009365024976432323, 0.017720244824886322, 0.02589871548116207, 0.04161275178194046, 0.007009172812104225, 0.01237757783383131, 0.01753021590411663, 0.00922334659844637, 0.03542235493659973, 0.02416388876736164, 0.021184498444199562, 0.005269817542284727, 0.010730900801718235, 0.01667400635778904, 0.07097139954566956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016932014841586351, 0.007397367153316736, 0.00505095673725009, 0.013727004639804363, 0.008426650427281857, 0.004913370590656996, 0.00806888286024332, 0.0014105546288192272, 0.015409188345074654, 0.004659511614590883, 0.015354563482105732, 0.009698937647044659, 0.0023472493048757315, 0.018569836392998695, 0.007272085640579462, 0.011816983111202717, 0.0035797692835330963, 0.002699097152799368, 0.3783096671104431, 0.0021020909771323204, 0.004110300913453102, 0.0034591169096529484, 0.01091521605849266, 0.0027854065410792828, 0.009290616028010845, 0.005520114675164223, 0.0005333103472366929, 0.00464845122769475, 0.003448956413194537, 0.003418238367885351, 0.0021628255490213633, 0.0008206189377233386, 0.03098294511437416, 0.049164917320013046, 0.009111269377171993, 0.0014106244780123234, 0.013619013130664825, 0.003927796147763729, 0.010522912256419659, 0.010993110947310925, 0.003679574467241764, 0.00490456260740757, 0.012196231633424759, 0.0048344796523451805, 0.014995209872722626, 0.005189650692045689, 0.0022167121060192585, 0.0031497133895754814, 0.005526701454073191, 0.006617135368287563, 0.0031810051295906305, 0.01514799427241087, 0.013562806881964207, 0.004237279295921326, 0.002632521092891693, 0.19457575678825378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008237955160439014, 0.0011021861573681235, 0.0031220861710608006, 0.00022442157205659896, 0.0037298868410289288, 0.002915892517194152, 0.005085465032607317, 0.0008838068461045623, 0.00926277320832014, 0.004700932186096907, 0.001860623131506145, 0.027159778401255608, 0.0097181536257267, 0.0034245275892317295, 0.001154307508841157, 0.006246273405849934, 0.010543489828705788, 0.0037246670108288527, 0.006952438037842512, 0.009845946915447712, 0.007886127568781376, 0.0018992938566952944, 0.0029974670615047216, 0.06107950955629349, 0.004512272775173187, 0.004721138160675764, 0.00046226821723394096, 0.004468247294425964, 0.0015912551898509264, 0.002805553376674652, 0.009265697561204433, 0.0004767330246977508, 0.23165962100028992, 0.013940823264420033, 0.004782911390066147, 0.018194641917943954, 0.0025942635256797075, 0.0013073856243863702, 0.048215556889772415, 0.03197609260678291, 0.025497296825051308, 0.0005729455733671784, 0.00294515211135149, 0.01059274934232235, 0.0074756876565515995, 0.00372405257076025, 0.0024108593352138996, 0.002562129171565175, 0.002607373520731926, 0.020812679082155228, 0.003921914380043745, 0.0038848230615258217, 0.005260447971522808, 0.002475242828950286, 0.0061891875229775906, 0.01066222507506609, 0.313672810792923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004794742446392775, 0.01890791766345501, 0.01721380278468132, 0.007100709248334169, 0.0020241946913301945, 0.006272223778069019, 0.005133738275617361, 0.0058711012825369835, 0.004393259063363075, 0.013738568872213364, 0.004544652067124844, 0.030259283259510994, 0.01611577905714512, 0.0019234662177041173, 0.0047247582115232944, 0.008249226026237011, 0.04445049539208412, 0.09105394035577774, 0.005174631252884865, 0.019701167941093445, 0.010995742864906788, 0.02791319414973259, 0.014828739687800407, 0.003664120566099882, 0.00905478373169899, 0.003333329688757658, 0.0701732486486435, 0.013297290541231632, 0.004903054796159267, 0.01133753638714552, 0.01069079339504242, 0.0353551022708416, 0.004358045291155577, 0.008307641372084618, 0.012669756077229977, 0.0024335223715752363, 0.0957312062382698, 0.01394872646778822, 0.0026199098210781813, 0.016642995178699493, 0.00320312287658453, 0.023950470611453056, 0.005335938651114702, 0.012418174184858799, 0.0014162989100441337, 0.014214362017810345, 0.03767954558134079, 0.03871936723589897, 0.00348130171187222, 0.0012380452826619148, 0.008086910471320152, 0.0037645348347723484, 0.001449565519578755, 0.015298578888177872, 0.004934289027005434, 0.0037745528388768435, 0.004259766545146704, 0.13286873698234558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04503532499074936, 0.004302056040614843, 0.0055083017796278, 0.00219797738827765, 0.001266554812900722, 0.0033053120132535696, 0.0008721289923414588, 0.000585163536015898, 0.002316295402124524, 0.0010320135625079274, 0.01580936834216118, 0.003968565259128809, 0.004611745476722717, 0.0064381747506558895, 0.00042246782686561346, 0.0012855796376243234, 0.009606435894966125, 0.0058593894354999065, 0.007529882248491049, 0.0016990662552416325, 0.02937769889831543, 0.004872395657002926, 0.003044107696041465, 0.011578529141843319, 0.013965173624455929, 0.010657408274710178, 0.0020342967472970486, 0.025530865415930748, 0.006312042009085417, 0.0005873999907635152, 0.20365899801254272, 0.006678525358438492, 0.0069997296668589115, 0.0010276768589392304, 0.001039825496263802, 0.015185636468231678, 0.005608999170362949, 0.005554940551519394, 0.007550687529146671, 0.017368555068969727, 0.005253619980067015, 0.011078810319304466, 0.005472158547490835, 0.012815194204449654, 0.014524647034704685, 0.024580111727118492, 0.0032435429748147726, 0.00066541344858706, 0.007344349287450314, 0.0065485695376992226, 0.0016209125751629472, 0.019422784447669983, 0.0036061627324670553, 0.0036065755411982536, 0.00809544138610363, 0.005796018056571484, 0.004775706212967634, 0.0007356410496868193, 0.3585289716720581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01020844280719757, 0.012764143757522106, 0.022042859345674515, 0.02109537646174431, 0.025539031252264977, 0.010448617860674858, 0.022474031895399094, 0.008215825073421001, 0.003216823562979698, 0.0021304478868842125, 0.00785481370985508, 0.013806243427097797, 0.0032275617122650146, 0.011878972873091698, 0.10451926290988922, 0.004443017765879631, 0.008832736872136593, 0.0014042543480172753, 0.003905914258211851, 0.0018710065633058548, 0.004515593871474266, 0.018842794001102448, 0.015113798901438713, 0.0010371904354542494, 0.004892957862466574, 0.01902064122259617, 0.0026056382339447737, 0.0005991904763504863, 0.002748731756582856, 0.003257681615650654, 0.002039050217717886, 0.0029562264680862427, 0.003106173826381564, 0.00596092501655221, 0.005011989269405603, 0.0024368595331907272, 0.002969736000522971, 0.04453042149543762, 0.002782036317512393, 0.01673274114727974, 0.007211856544017792, 0.008907636627554893, 0.02336197718977928, 0.0067231543362140656, 0.018579695373773575, 0.0059683965519070625, 0.010211238637566566, 0.0024910748470574617, 0.005918418522924185, 0.013073512353003025, 0.011021598242223263, 0.0052891261875629425, 0.0400802418589592, 0.004756845999509096, 0.02048637345433235, 0.010517526417970657, 0.0022047339007258415, 0.004131135065108538, 0.0032093008048832417, 0.3348163664340973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0722503662109375, 0.0012917591957375407, 0.0217076875269413, 0.005769198294728994, 0.01822051592171192, 0.002277807332575321, 0.004644010681658983, 0.059906695038080215, 0.009886977262794971, 0.010211978107690811, 0.0012262281961739063, 0.0039204503409564495, 0.006255723536014557, 0.007746429648250341, 0.0033371318131685257, 0.0030585008207708597, 0.004610087256878614, 0.006652890704572201, 0.01044499035924673, 0.021403392776846886, 0.005797063931822777, 0.040059491991996765, 0.005209536757320166, 0.008920872583985329, 0.01524642575532198, 0.011922558769583702, 0.021649369969964027, 0.0061541395261883736, 0.029287321493029594, 0.01153295673429966, 0.002079537371173501, 0.01946263574063778, 0.030383959412574768, 0.010310545563697815, 0.019201742485165596, 0.010554924607276917, 0.015649719163775444, 0.033775631338357925, 0.016202347353100777, 0.0037265033461153507, 0.026109525933861732, 0.0012330826139077544, 0.013421459123492241, 0.007026463747024536, 0.006736879236996174, 0.007217103615403175, 0.02361374907195568, 0.015857620164752007, 0.02234598621726036, 0.01072787307202816, 0.010855352506041527, 0.01093840878456831, 0.018635530024766922, 0.006412152200937271, 0.007171337958425283, 0.009336731396615505, 0.01366347260773182, 0.004476278088986874, 0.0023246132768690586, 0.004279738757759333, 0.18566648662090302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01188045833259821, 0.012290392071008682, 0.02978324703872204, 0.00722678704187274, 0.005194989964365959, 0.00535984430462122, 0.001504144398495555, 0.011057980358600616, 0.001247451058588922, 0.013447198085486889, 0.008460749872028828, 0.0058327424339950085, 0.01444983296096325, 0.0046253209002316, 0.002379646757617593, 0.027186011895537376, 0.007121799048036337, 0.008944006636738777, 0.007544179912656546, 0.020999709144234657, 0.005961914546787739, 0.023999322205781937, 0.018712686374783516, 0.008889451622962952, 0.09450817853212357, 0.0034847441129386425, 0.002165390644222498, 0.012710350565612316, 0.0190616175532341, 0.014170999638736248, 0.004141929559409618, 0.027191858738660812, 0.0021587780211120844, 0.0023232267703861, 0.020040595903992653, 0.008846883662045002, 0.005669273901730776, 0.04840158671140671, 0.007818307727575302, 0.008360877633094788, 0.0224543996155262, 0.019451454281806946, 0.0020592957735061646, 0.013004033826291561, 0.003385653253644705, 0.015635203570127487, 0.013962185941636562, 0.012938501313328743, 0.009011484682559967, 0.0038359377067536116, 0.0035046106204390526, 0.006530271377414465, 0.0034658079966902733, 0.008442793972790241, 0.01563282497227192, 0.011704308912158012, 0.002018291037529707, 0.005128169432282448, 0.004665544722229242, 0.004193815868347883, 0.019233644008636475, 0.254587322473526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04584924131631851, 0.00672231987118721, 0.019119342789053917, 0.0019320822320878506, 0.0033652596175670624, 0.003447039518505335, 0.006920590065419674, 0.006725537125021219, 0.00997066404670477, 0.008147078566253185, 0.0021196380257606506, 0.008117295801639557, 0.0019397838041186333, 0.011548088863492012, 0.004603203851729631, 0.0025690190959721804, 0.009152685292065144, 0.006143488921225071, 0.0069351946003735065, 0.01860016956925392, 0.007750962860882282, 0.01000980194658041, 0.009763703681528568, 0.021375786513090134, 0.04547569528222084, 0.008384906686842442, 0.007434472907334566, 0.11732633411884308, 0.012685943394899368, 0.022719360888004303, 0.011422325856983662, 0.00997949205338955, 0.035697657614946365, 0.0071430690586566925, 0.008406917564570904, 0.006951163988560438, 0.012215758673846722, 0.009806371293962002, 0.007278507575392723, 0.029366785660386086, 0.0041969395242631435, 0.011910154484212399, 0.0071335737593472, 0.016316968947649002, 0.007689595688134432, 0.005950057413429022, 0.00514594092965126, 0.0036529425997287035, 0.008974476717412472, 0.008630973286926746, 0.009483392350375652, 0.02304403856396675, 0.007824646309018135, 0.004788550548255444, 0.005009687505662441, 0.004671589937061071, 0.012292386963963509, 0.0042684851214289665, 0.01534341648221016, 0.0013062971411272883, 0.008098228834569454, 0.01542896218597889, 0.22371599078178406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016001194715499878, 0.0016543685924261808, 0.00708391610532999, 0.003167096758261323, 0.0019323091255500913, 0.007048960775136948, 0.014467490836977959, 0.001792912371456623, 0.0023159708362072706, 0.0070025380700826645, 0.0008484511054120958, 0.0004049990384373814, 0.003787467023357749, 0.001538249314762652, 0.0019527155673131347, 0.0008716213633306324, 0.03160085529088974, 0.038884155452251434, 0.001221084501594305, 0.004574757069349289, 0.007730104494839907, 0.013741166330873966, 0.0004946875851601362, 0.0052768816240131855, 0.0016779749421402812, 0.0016001755138859153, 0.015307695604860783, 0.0030409132596105337, 0.0020481033716350794, 0.0016219409881159663, 0.008829471655189991, 0.27115076780319214, 0.0032649401109665632, 0.009764714166522026, 0.00407643336802721, 0.010030399076640606, 0.013168197125196457, 0.02514301985502243, 0.002312620636075735, 0.0004271409416105598, 0.002208132529631257, 0.002837996929883957, 0.01927502639591694, 0.010433176532387733, 0.002538552274927497, 0.009862344712018967, 0.029206451028585434, 0.004643693566322327, 0.001422639936208725, 0.0029661166481673717, 0.003708514152094722, 0.0060315500013530254, 0.002327677793800831, 0.004443814978003502, 0.010632889345288277, 0.0007841152255423367, 0.0023982063867151737, 0.01331950630992651, 0.008758303709328175, 0.0025675904471427202, 0.003710841992869973, 0.004833157639950514, 0.0038926878478378057, 0.29833853244781494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006395929958671331, 0.0013731581857427955, 0.0029011876322329044, 0.002697212854400277, 0.01983136124908924, 0.031340014189481735, 0.003554331371560693, 0.01192888617515564, 0.0034272854682058096, 0.024738933891057968, 0.002991295186802745, 0.022408049553632736, 0.0015507538337260485, 0.0051251850090920925, 0.06002403795719147, 0.004850292578339577, 0.0059364549815654755, 0.0014850905863568187, 0.0064056566916406155, 0.011243999004364014, 0.0047606113366782665, 0.01895405724644661, 0.015499163419008255, 0.007541003171354532, 0.0036064721643924713, 0.005440082401037216, 0.010230682790279388, 0.015554513782262802, 0.0025860704481601715, 0.14753341674804688, 0.0010915797902271152, 0.0008003483526408672, 0.005214742384850979, 0.0011931696208193898, 0.009809947572648525, 0.011659081093966961, 0.0030341215897351503, 0.002563490765169263, 0.002252135891467333, 0.0374295599758625, 0.0016507019754499197, 0.001854805275797844, 0.0034700357355177402, 0.00382770923897624, 0.004301141016185284, 0.006862688343971968, 0.03355232998728752, 0.00632590614259243, 0.001898603281006217, 0.0009126406512223184, 0.005938714370131493, 0.0030192257836461067, 0.020162293687462807, 0.010102842003107071, 0.0019075206946581602, 0.00690824817866087, 0.0030568991787731647, 0.016738377511501312, 0.0018303939141333103, 0.02164851315319538, 0.006294923834502697, 0.0035509380977600813, 0.006226328667253256, 0.00047629207256250083, 0.290518581867218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025313422083854675, 0.004331940785050392, 0.003008210565894842, 0.047908175736665726, 0.01234738714993, 0.0019053806317970157, 0.005110830068588257, 0.013744588010013103, 0.025476060807704926, 0.006633155047893524, 0.008854337967932224, 0.00683409720659256, 0.005320100579410791, 0.02838602289557457, 0.024221953004598618, 0.0032430384308099747, 0.005725898314267397, 0.003146706847473979, 0.011064762249588966, 0.007010491564869881, 0.025742866098880768, 0.004896165803074837, 0.026638289913535118, 0.001739602885209024, 0.015196387656033039, 0.03589063882827759, 0.024169426411390305, 0.013929287903010845, 0.02667139656841755, 0.0014070963952690363, 0.007132736966013908, 0.0057308245450258255, 0.005421224515885115, 0.018696323037147522, 0.009124391712248325, 0.007567533291876316, 0.004651786293834448, 0.01267512608319521, 0.00294118607416749, 0.003984762821346521, 0.017380760982632637, 0.010522225871682167, 0.01716662384569645, 0.011098314076662064, 0.008064315654337406, 0.015305784530937672, 0.005448461510241032, 0.013639265671372414, 0.05860838294029236, 0.006071393843740225, 0.013687839731574059, 0.02293947897851467, 0.059191055595874786, 0.016869278624653816, 0.006833675317466259, 0.010449242778122425, 0.002074267016723752, 0.011878152377903461, 0.007493714801967144, 0.023957110941410065, 0.00933118723332882, 0.012952414341270924, 0.004010144155472517, 0.00924493558704853, 0.003250457113608718, 0.11873792111873627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009218558669090271, 0.020170671865344048, 0.024668628349900246, 0.0046234712935984135, 0.006878236308693886, 0.004518157336860895, 0.035705018788576126, 0.003938242793083191, 0.004210015293210745, 0.02211204171180725, 0.010494722984731197, 0.004316337872296572, 0.005176903679966927, 0.006848510354757309, 0.004257493186742067, 0.005970318801701069, 0.021789195016026497, 0.007007976528257132, 0.016452867537736893, 0.013880675658583641, 0.007273478899151087, 0.0112222321331501, 0.007416968699544668, 0.008788996376097202, 0.03236033394932747, 0.013904561288654804, 0.0023777452297508717, 0.006456543691456318, 0.014687960967421532, 0.007804807275533676, 0.0041623045690357685, 0.027906060218811035, 0.0255349799990654, 0.040685638785362244, 0.021615978330373764, 0.008770789951086044, 0.011058934964239597, 0.020245226100087166, 0.021452516317367554, 0.005955323111265898, 0.021884609013795853, 0.006720420904457569, 0.02111675776541233, 0.025304652750492096, 0.018820608034729958, 0.007534185890108347, 0.00935406144708395, 0.009597702883183956, 0.009819281287491322, 0.05157674103975296, 0.005068344995379448, 0.011518726125359535, 0.004789656028151512, 0.01227718498557806, 0.0175370704382658, 0.020781023427844048, 0.023304937407374382, 0.003517717821523547, 0.007219740655273199, 0.010099092498421669, 0.01719142124056816, 0.044561464339494705, 0.047798097133636475, 0.02089712582528591, 0.007531940937042236, 0.0049883355386555195, 0.02726966142654419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.049157578498125076, 0.006387006025761366, 0.010307992808520794, 0.0015623625367879868, 0.014699040912091732, 0.003207297995686531, 0.01493803970515728, 0.007885295897722244, 0.03490585461258888, 0.005887523293495178, 0.009432566352188587, 0.01600620150566101, 0.014561139978468418, 0.018596291542053223, 0.012153329327702522, 0.014575113542377949, 0.011927296407520771, 0.00545849371701479, 0.014462251216173172, 0.00717591866850853, 0.005779135040938854, 0.010497169569134712, 0.010705261491239071, 0.002862847177311778, 0.005511810537427664, 0.03742336854338646, 0.003715151222422719, 0.0039850021712481976, 0.004508448299020529, 0.005085168406367302, 0.017405662685632706, 0.014285522513091564, 0.023338034749031067, 0.044983766973018646, 0.002649064641445875, 0.009047246538102627, 0.0056692445650696754, 0.015246219001710415, 0.032749321311712265, 0.008472262881696224, 0.008113871328532696, 0.003096281783655286, 0.008937210775911808, 0.009172836318612099, 0.008461356163024902, 0.0073782349936664104, 0.02194523997604847, 0.011699962429702282, 0.004510478116571903, 0.02888219803571701, 0.017867982387542725, 0.013917521573603153, 0.020627813413739204, 0.019251694902777672, 0.0059213959611952305, 0.010134989395737648, 0.0291603896766901, 0.005750115029513836, 0.021839596331119537, 0.01161892432719469, 0.022330520674586296, 0.005201295949518681, 0.004253945779055357, 0.022550949826836586, 0.004272465594112873, 0.006681311875581741, 0.01501673087477684, 0.11419843882322311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026058396324515343, 0.006397276185452938, 0.022038837894797325, 0.0019084068480879068, 0.004381000995635986, 0.002417647046968341, 0.018216826021671295, 0.0030820751562714577, 0.004568250849843025, 0.009469696320593357, 0.0027353367768228054, 0.007563746068626642, 0.00238816044293344, 0.009468344040215015, 0.008441338315606117, 0.003385532647371292, 0.004033115692436695, 0.002373006194829941, 0.06488654017448425, 0.0065388125367462635, 0.007402211427688599, 0.015034875832498074, 0.003215284086763859, 0.0058821397833526134, 0.008444301784038544, 0.008873118087649345, 0.001322457566857338, 0.008566916920244694, 0.0036092279478907585, 0.005050024017691612, 0.0013102416414767504, 0.011969276703894138, 0.03316192701458931, 0.10806974768638611, 0.011766327545046806, 0.010055406019091606, 0.008557075634598732, 0.011397109366953373, 0.013760348781943321, 0.010377525351941586, 0.012111400254070759, 0.0052505843341350555, 0.02420426718890667, 0.004708268214017153, 0.007606144063174725, 0.008824894204735756, 0.019862757995724678, 0.020484628155827522, 0.00321030430495739, 0.01366741955280304, 0.003398469416424632, 0.01213555596768856, 0.006784997880458832, 0.007326758466660976, 0.004952147137373686, 0.03463035076856613, 0.01870151050388813, 0.0029371583368629217, 0.004854138940572739, 0.013765212148427963, 0.009116132743656635, 0.01508844643831253, 0.020717816427350044, 0.020558007061481476, 0.005663073621690273, 0.0032139138784259558, 0.022933902218937874, 0.102352075278759, 0.07276183366775513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0315084233880043, 0.004401307087391615, 0.014487304724752903, 0.0032519614323973656, 0.0038836104795336723, 0.002503091236576438, 0.022781480103731155, 0.0011194625403732061, 0.008952423930168152, 0.00461863586679101, 0.003135805483907461, 0.004034984856843948, 0.0014834783505648375, 0.01543542928993702, 0.01015190128237009, 0.0018978905864059925, 0.019078562036156654, 0.0030615890864282846, 0.010997962206602097, 0.003819139674305916, 0.010139698162674904, 0.005553852766752243, 0.004588517360389233, 0.002327654743567109, 0.009761204943060875, 0.014819053933024406, 0.006832477170974016, 0.022167453542351723, 0.007546370383352041, 0.0026815151795744896, 0.003074639244005084, 0.021640244871377945, 0.03484846279025078, 0.03767988458275795, 0.003402155824005604, 0.0018916744738817215, 0.00819576345384121, 0.016762472689151764, 0.013935104012489319, 0.008959488943219185, 0.0014245385536924005, 0.007683164440095425, 0.09665919095277786, 0.017474522814154625, 0.011171307414770126, 0.008492634631693363, 0.006475386675447226, 0.0042150625959038734, 0.007815917022526264, 0.008986436761915684, 0.005086776800453663, 0.024636542424559593, 0.012254721485078335, 0.010588286444544792, 0.004498613998293877, 0.006658271886408329, 0.017234312370419502, 0.007061421405524015, 0.007414802443236113, 0.010048530995845795, 0.004066186957061291, 0.005404862109571695, 0.06545650959014893, 0.03339363634586334, 0.006395976059138775, 0.005500949919223785, 0.016272790729999542, 0.07143640518188477, 0.04925427958369255, 0.05952588468790054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.037280015647411346, 0.012474583461880684, 0.012312482111155987, 0.0014891641912981868, 0.002587591763585806, 0.0015983402263373137, 0.012309042736887932, 0.0017925553256645799, 0.010969633236527443, 0.008589698933064938, 0.0069903600960969925, 0.006434107664972544, 0.0034225592389702797, 0.0071334573440253735, 0.0030882502906024456, 0.004238879308104515, 0.009350446984171867, 0.0021354067139327526, 0.01983133889734745, 0.003428117372095585, 0.00597437284886837, 0.010971477255225182, 0.006145712919533253, 0.0019955667667090893, 0.006845877040177584, 0.01372660044580698, 0.0003552734269760549, 0.009161707013845444, 0.005674002692103386, 0.005084565840661526, 0.0010931837605312467, 0.014740406535565853, 0.03703831136226654, 0.07345020025968552, 0.005392765160650015, 0.004750611260533333, 0.005935577675700188, 0.011527829803526402, 0.021028436720371246, 0.005499451886862516, 0.005934372078627348, 0.004617177881300449, 0.013622266240417957, 0.011640183627605438, 0.012096553109586239, 0.011730283498764038, 0.014994160272181034, 0.016453251242637634, 0.0033288421109318733, 0.027639370411634445, 0.009981472045183182, 0.0065823886543512344, 0.005067234858870506, 0.01616153120994568, 0.004727439489215612, 0.023234177380800247, 0.02337644062936306, 0.0032566585578024387, 0.0028821860905736685, 0.008548418991267681, 0.005945565178990364, 0.011145400814712048, 0.03127817064523697, 0.01955028437077999, 0.00654313201084733, 0.00101856526453048, 0.011722993105649948, 0.11743243038654327, 0.038952507078647614, 0.03452296182513237, 0.08216562867164612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06454750150442123, 0.002681942656636238, 0.007684021256864071, 0.004792196676135063, 0.0035700646694749594, 0.0015777760418131948, 0.007309595122933388, 0.0016195044154301286, 0.011380776762962341, 0.004670222755521536, 0.005227821879088879, 0.008073106408119202, 0.0028526373207569122, 0.00752678420394659, 0.00871354527771473, 0.0035465226974338293, 0.009006928652524948, 0.0026476557832211256, 0.02474725991487503, 0.0024565330240875483, 0.02675522491335869, 0.007867678068578243, 0.006200894713401794, 0.0020799520425498486, 0.003791451919823885, 0.021919257938861847, 0.0013813377590849996, 0.005040219984948635, 0.005239573772996664, 0.002150584477931261, 0.0025072875432670116, 0.006807105615735054, 0.028635187074542046, 0.06486747413873672, 0.006763642653822899, 0.0037626088596880436, 0.007088946644216776, 0.00956161879003048, 0.02213168889284134, 0.007519689854234457, 0.006930573843419552, 0.003228304907679558, 0.03694219887256622, 0.012394720688462257, 0.012917349115014076, 0.021795030683279037, 0.012577568180859089, 0.014783882535994053, 0.008867587894201279, 0.017603280022740364, 0.006573367863893509, 0.007681054063141346, 0.011882979422807693, 0.009749780409038067, 0.007752439938485622, 0.01674792543053627, 0.018001411110162735, 0.0030017164535820484, 0.005938170477747917, 0.01496399100869894, 0.01170844491571188, 0.004962204955518246, 0.007817810401320457, 0.011703597381711006, 0.003744673216715455, 0.016001690179109573, 0.018261803314089775, 0.05104752629995346, 0.06859706342220306, 0.03778151422739029, 0.04920659959316254, 0.04212985187768936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005908164195716381, 0.007808343507349491, 0.005598516669124365, 0.004273752216249704, 0.006039798725396395, 0.003209046320989728, 0.014680232852697372, 0.004476794041693211, 0.020725278183817863, 0.007771092001348734, 0.008783610537648201, 0.0009419075213372707, 0.0023790127597749233, 0.009701997973024845, 0.0011148814810439944, 0.009120541624724865, 0.004020305350422859, 0.0014404610265046358, 0.02567921206355095, 0.005005962215363979, 0.0032166873570531607, 0.0031279681716114283, 0.010400131344795227, 0.002810875652357936, 0.00714097311720252, 0.01915612630546093, 0.0005381341907195747, 0.0021311070304363966, 0.0034808332566171885, 0.0059296609833836555, 0.0013036447344347835, 0.018937911838293076, 0.00779295340180397, 0.0805399939417839, 0.003999290056526661, 0.008326737210154533, 0.0015645407838746905, 0.004476228728890419, 0.021992769092321396, 0.0005301209166646004, 0.004903345834463835, 0.0017404863610863686, 0.006864090450108051, 0.003087218152359128, 0.004028656519949436, 0.0035162395797669888, 0.003694371785968542, 0.009176764637231827, 0.0012750159949064255, 0.03975897654891014, 0.009478413499891758, 0.006546347867697477, 0.006145707331597805, 0.019602790474891663, 0.0051511311903595924, 0.014344586990773678, 0.004881135653704405, 0.0013774000108242035, 0.0025167407002300024, 0.0040317727252841, 0.0029261894524097443, 0.009583842009305954, 0.004038405138999224, 0.024029290303587914, 0.002661863574758172, 0.0018149182433262467, 0.015180661343038082, 0.0458456315100193, 0.07209859788417816, 0.026253193616867065, 0.15707917511463165, 0.05307193100452423, 0.0772194191813469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015754586085677147, 0.00861910916864872, 0.006375160068273544, 0.0014682677574455738, 0.0033631862606853247, 0.012610103003680706, 0.03343409299850464, 0.0029779886826872826, 0.006394262425601482, 0.006868691649287939, 0.0049062371253967285, 0.002395465038716793, 0.010954960249364376, 0.0030241776257753372, 0.002651403658092022, 0.005506500601768494, 0.021450145170092583, 0.0028211770113557577, 0.01164462324231863, 0.006175059825181961, 0.0030269452836364508, 0.005338694434612989, 0.017157375812530518, 0.009143655188381672, 0.008903789333999157, 0.01704240031540394, 0.0009078234434127808, 0.004587825387716293, 0.004132924135774374, 0.017765125259757042, 0.0016405223868787289, 0.02068411372601986, 0.012687966227531433, 0.05136847868561745, 0.009653805755078793, 0.011112907901406288, 0.004859606735408306, 0.004317925311625004, 0.010480972938239574, 0.0024200526531785727, 0.022816764190793037, 0.004189509432762861, 0.009857448749244213, 0.012288203462958336, 0.0033738338388502598, 0.0042902822606265545, 0.008184938691556454, 0.0077324919402599335, 0.002226528711616993, 0.061694253236055374, 0.019731316715478897, 0.005666404962539673, 0.002294193720445037, 0.03219781070947647, 0.03021516464650631, 0.01775144599378109, 0.007450731936842203, 0.004287333227694035, 0.003735553240403533, 0.007267357315868139, 0.008113112300634384, 0.01608198508620262, 0.011870995163917542, 0.015203189104795456, 0.007864193990826607, 0.000981395598500967, 0.015269230119884014, 0.04155576601624489, 0.02554631605744362, 0.020448515191674232, 0.07077280431985855, 0.026249675080180168, 0.029201455414295197, 0.05696156993508339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04975050315260887, 0.005392588675022125, 0.021973373368382454, 0.00112037337385118, 0.0037093330174684525, 0.007933830842375755, 0.022328313440084457, 0.002036835765466094, 0.004735676571726799, 0.003114163177087903, 0.00264074862934649, 0.0031277022790163755, 0.003640072885900736, 0.006766779813915491, 0.004135506693273783, 0.004304026253521442, 0.006622024811804295, 0.00241300486959517, 0.01993177831172943, 0.0032035154290497303, 0.004651095252484083, 0.005154514219611883, 0.0024362020194530487, 0.00563359959051013, 0.0020201210863888264, 0.016444267705082893, 0.0006555954460054636, 0.005500332918018103, 0.003156435675919056, 0.005813685245811939, 0.002477217698469758, 0.020920434966683388, 0.011218775995075703, 0.05313276872038841, 0.003241633763536811, 0.006137268617749214, 0.005121215712279081, 0.016492631286382675, 0.019120996817946434, 0.004811538383364677, 0.004510338883846998, 0.00547884963452816, 0.04306136444211006, 0.010169547982513905, 0.006046830210834742, 0.006040183361619711, 0.010042345151305199, 0.006210548337548971, 0.003511185059323907, 0.03612858057022095, 0.010399308055639267, 0.009443370625376701, 0.006501233670860529, 0.008546021766960621, 0.015251439064741135, 0.011617868207395077, 0.01021978072822094, 0.0016993270255625248, 0.0068929665721952915, 0.00677498010918498, 0.00785574410110712, 0.004054936580359936, 0.008923460729420185, 0.025105340406298637, 0.003339513437822461, 0.0015865605091676116, 0.014814749360084534, 0.07920324057340622, 0.04026759788393974, 0.025969840586185455, 0.060462117195129395, 0.023951759561896324, 0.030264506116509438, 0.03320110961794853, 0.04943292587995529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04539639502763748, 0.006585395894944668, 0.0078749880194664, 0.0016952953301370144, 0.005098880734294653, 0.005000532604753971, 0.02238953672349453, 0.002933851210400462, 0.008799749426543713, 0.008002555929124355, 0.0058236392214894295, 0.002577004721388221, 0.006057269871234894, 0.01085218507796526, 0.007388563826680183, 0.001441293628886342, 0.021129287779331207, 0.002794032683596015, 0.002825577976182103, 0.007344093173742294, 0.00947638601064682, 0.007130651269108057, 0.00711045553907752, 0.0012723315740004182, 0.0013823334593325853, 0.020033087581396103, 0.010608118027448654, 0.007508938200771809, 0.0054203602485358715, 0.003916551824659109, 0.0012539206072688103, 0.02660125307738781, 0.008122389204800129, 0.02162204310297966, 0.006496249698102474, 0.007784624584019184, 0.006553192622959614, 0.028497232124209404, 0.003844963852316141, 0.0025604721158742905, 0.003430443350225687, 0.003495871787890792, 0.020706258714199066, 0.011129586957395077, 0.005228283815085888, 0.008193797431886196, 0.014782190322875977, 0.012967141345143318, 0.003904359880834818, 0.009143693372607231, 0.020553626120090485, 0.010384395718574524, 0.009957361035048962, 0.01989027112722397, 0.008096867240965366, 0.0054528191685676575, 0.006546430289745331, 0.03034176304936409, 0.003936916124075651, 0.012995816767215729, 0.004331254865974188, 0.003538567805662751, 0.008946455083787441, 0.030724145472049713, 0.0038838896434754133, 0.0011747374664992094, 0.012440868653357029, 0.05946023389697075, 0.027026401832699776, 0.013349564746022224, 0.036215007305145264, 0.011767678894102573, 0.01676851324737072, 0.01927035301923752, 0.02524806559085846, 0.13551069796085358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021576078608632088, 0.004907738417387009, 0.006949588190764189, 0.0011917819501832128, 0.006579960696399212, 0.002785684308037162, 0.008973435498774052, 0.002299277577549219, 0.00934974942356348, 0.003887547180056572, 0.005988867487758398, 0.002372461836785078, 0.004395289812237024, 0.011656672693789005, 0.0032014362514019012, 0.006063899025321007, 0.011858724057674408, 0.0016809297958388925, 0.016467005014419556, 0.013497360050678253, 0.007799702696502209, 0.00311087048612535, 0.008437308482825756, 0.0015652149450033903, 0.007154612801969051, 0.008466658182442188, 0.0009134952560998499, 0.011455319821834564, 0.005644898861646652, 0.0036135741975158453, 0.001237065065652132, 0.013917866162955761, 0.008780200965702534, 0.033294375985860825, 0.0047446382232010365, 0.006690916605293751, 0.00451720179989934, 0.01876179128885269, 0.0070269908756017685, 0.00208259210921824, 0.0037094280123710632, 0.005857591051608324, 0.01001222524791956, 0.019774634391069412, 0.00263867131434381, 0.010042963549494743, 0.004272058606147766, 0.023365577682852745, 0.0044719148427248, 0.008077242411673069, 0.012191575020551682, 0.01132887415587902, 0.015523144975304604, 0.010950185358524323, 0.007570079993456602, 0.014226126484572887, 0.006506209261715412, 0.006253314204514027, 0.003606684971600771, 0.004857070744037628, 0.0026598162949085236, 0.006555245257914066, 0.010175720788538456, 0.013349276967346668, 0.004135210067033768, 0.0010111952433362603, 0.014746645465493202, 0.08605149388313293, 0.04300285503268242, 0.01475516241043806, 0.04054208844900131, 0.0331171452999115, 0.022294389083981514, 0.020805254578590393, 0.05022674426436424, 0.040558621287345886, 0.1058788150548935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01887490041553974, 0.0071854013949632645, 0.010427475906908512, 0.0010362501488998532, 0.0038448094855993986, 0.0004378663143143058, 0.008415973745286465, 0.0025223924312740564, 0.016139820218086243, 0.0026782189961522818, 0.0037939283065497875, 0.0036102894227951765, 0.0040907179936766624, 0.010215556249022484, 0.0013067331165075302, 0.002397273201495409, 0.0030306358821690083, 0.0012495719129219651, 0.012724269181489944, 0.0038674473762512207, 0.006415031850337982, 0.00450544198974967, 0.0069743795320391655, 0.0012177641037851572, 0.0028826494235545397, 0.011344684287905693, 0.0006402177386917174, 0.0038019935600459576, 0.0018903912277892232, 0.003236051881685853, 0.002116564428433776, 0.019204065203666687, 0.01620323397219181, 0.042285628616809845, 0.0024575218558311462, 0.002221126342192292, 0.0022782417945563793, 0.00827835127711296, 0.015797913074493408, 0.002415589289739728, 0.0036039676051586866, 0.002847939496859908, 0.009257613681256771, 0.003757544793188572, 0.005772273521870375, 0.009576654992997646, 0.0036723159719258547, 0.01318279467523098, 0.00143501500133425, 0.02247714065015316, 0.00831518229097128, 0.006837888155132532, 0.006014207843691111, 0.014256738126277924, 0.0013781433226540685, 0.007298365235328674, 0.012470623478293419, 0.002003297209739685, 0.004836311563849449, 0.0038668138440698385, 0.004912207834422588, 0.005240717437118292, 0.00897906068712473, 0.025495076552033424, 0.001954115927219391, 0.0014715995639562607, 0.009616643190383911, 0.11608689278364182, 0.045064132660627365, 0.02936086617410183, 0.07706373929977417, 0.029317323118448257, 0.026609422639012337, 0.026844315230846405, 0.033157020807266235, 0.025608088821172714, 0.042295608669519424, 0.07404589653015137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025621002539992332, 0.009391603991389275, 0.003181176958605647, 0.0009633487788960338, 0.002636962803080678, 0.004924745298922062, 0.014674303121864796, 0.0037761968560516834, 0.02112487703561783, 0.006249704863876104, 0.00509117916226387, 0.003872630186378956, 0.004828595090657473, 0.010905938223004341, 0.004871817771345377, 0.005751288495957851, 0.0013406897196546197, 0.0006802399293519557, 0.01418157946318388, 0.002456100657582283, 0.0020594196394085884, 0.005307791288942099, 0.01429247297346592, 0.0025566064286977053, 0.002040521241724491, 0.016045717522501945, 0.0005586692132055759, 0.005322025157511234, 0.003352114465087652, 0.021004464477300644, 0.00050629727775231, 0.005311304237693548, 0.008908199146389961, 0.05397491157054901, 0.005855257157236338, 0.0035204393789172173, 0.0014481921680271626, 0.0023284978233277798, 0.00784038845449686, 0.002965357853099704, 0.004814694635570049, 0.003268565284088254, 0.0041758217848837376, 0.0010949933202937245, 0.0033006160520017147, 0.0035591386258602142, 0.00834773387759924, 0.008110295981168747, 0.001512182760052383, 0.026909315958619118, 0.01954074390232563, 0.006371179595589638, 0.0027278747875243425, 0.020735900849103928, 0.0038224298041313887, 0.013707383535802364, 0.006192004308104515, 0.0032643459271639585, 0.0012975867139175534, 0.004215509630739689, 0.0018264008685946465, 0.0043031638488173485, 0.006978743243962526, 0.007042621728032827, 0.009418193250894547, 0.0009499178850091994, 0.006302273366600275, 0.08166079223155975, 0.01390603557229042, 0.03492089360952377, 0.06349649280309677, 0.026008741930127144, 0.013954469002783298, 0.02427157200872898, 0.03994609788060188, 0.024443091824650764, 0.04046075791120529, 0.07967748492956161, 0.061741285026073456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09513615071773529, 0.00878631416708231, 0.021946806460618973, 0.0007825913489796221, 0.0053291842341423035, 0.009850599803030491, 0.007058675866574049, 0.0024284610990434885, 0.004928936716169119, 0.0066999951377511024, 0.004527274519205093, 0.0035153906792402267, 0.0060681807808578014, 0.019782308489084244, 0.005821318365633488, 0.0030286069959402084, 0.004422470927238464, 0.0053914082236588, 0.022329676896333694, 0.006246819626539946, 0.011253608390688896, 0.006817783694714308, 0.0015205148374661803, 0.020038418471813202, 0.002559574320912361, 0.010554298758506775, 0.0014933033380657434, 0.019176941365003586, 0.004420280456542969, 0.013833023607730865, 0.004068570211529732, 0.018650881946086884, 0.008299225941300392, 0.021003523841500282, 0.004944875370711088, 0.03477654606103897, 0.00550858536735177, 0.015109904110431671, 0.012712342664599419, 0.006582045461982489, 0.00786941684782505, 0.005629196763038635, 0.009900401346385479, 0.004324655048549175, 0.009175093844532967, 0.01058234740048647, 0.020841512829065323, 0.011631237342953682, 0.003074632491916418, 0.018706586211919785, 0.0075778779573738575, 0.018731985241174698, 0.005134049337357283, 0.005640239454805851, 0.006569202058017254, 0.016987066715955734, 0.014406933449208736, 0.003978846129029989, 0.009490177035331726, 0.0034028079826384783, 0.005931521765887737, 0.00671964418143034, 0.020928937941789627, 0.02898976393043995, 0.01154800783842802, 0.000872915901709348, 0.009507202543318272, 0.05767035484313965, 0.017836919054389, 0.011327100917696953, 0.02354496344923973, 0.012608762830495834, 0.01355887483805418, 0.009464329108595848, 0.020177271217107773, 0.00938870757818222, 0.008790731430053711, 0.024491041898727417, 0.021284038200974464, 0.024299269542098045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012207796797156334, 0.0028113964945077896, 0.011645170859992504, 0.0007908982806839049, 0.010087139904499054, 0.005120361689478159, 0.014150175265967846, 0.009012431837618351, 0.011680123396217823, 0.0035454395692795515, 0.001137056271545589, 0.0028244126588106155, 0.0026934428606182337, 0.002736819675192237, 0.004252690821886063, 0.01025024987757206, 0.003809624118730426, 0.0013947257539257407, 0.011497639119625092, 0.017427872866392136, 0.002933863550424576, 0.00941457413136959, 0.005361387971788645, 0.004618819337338209, 0.008543702773749828, 0.007924842648208141, 0.0007994340267032385, 0.00616837851703167, 0.009728281758725643, 0.019776679575443268, 0.0008693922427482903, 0.009109756909310818, 0.022013582289218903, 0.034748271107673645, 0.003118186956271529, 0.0033482476137578487, 0.00254090316593647, 0.00468161515891552, 0.026654621586203575, 0.001963395392522216, 0.005225786007940769, 0.0026472543831914663, 0.013448971323668957, 0.007227733265608549, 0.00238293525762856, 0.0040932814590632915, 0.0098270820453763, 0.030203165486454964, 0.006256679072976112, 0.02778780460357666, 0.01433769054710865, 0.0022443935740739107, 0.007093829568475485, 0.008676299825310707, 0.011065138503909111, 0.005355758126825094, 0.014474313706159592, 0.001653612474910915, 0.0016608727164566517, 0.008077087812125683, 0.01260350551456213, 0.007358535658568144, 0.009772527031600475, 0.010720412246882915, 0.012331034988164902, 0.0020910254679620266, 0.011144266463816166, 0.07681988179683685, 0.014932271093130112, 0.02499585598707199, 0.03499689698219299, 0.0245729461312294, 0.015838248655200005, 0.026606054976582527, 0.020937953144311905, 0.010989174246788025, 0.029240287840366364, 0.030067341402173042, 0.03528454527258873, 0.007286279462277889, 0.07427789270877838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015755578875541687, 0.006470681633800268, 0.024319415912032127, 0.0017275117570534348, 0.0032686106860637665, 0.0029150755144655704, 0.007981483824551105, 0.00213953317143023, 0.007069997489452362, 0.0022766899783164263, 0.0029579924885183573, 0.003251400077715516, 0.004350878298282623, 0.007617610972374678, 0.003113882150501013, 0.0026738320011645555, 0.01195524912327528, 0.006714265327900648, 0.010750992223620415, 0.003646356984972954, 0.009152278304100037, 0.015363438986241817, 0.004007413052022457, 0.00307254190556705, 0.006243362557142973, 0.010105526074767113, 0.0018214709125459194, 0.01121203787624836, 0.006697699893265963, 0.005796059500426054, 0.0036377545911818743, 0.03466665744781494, 0.016215940937399864, 0.02727956511080265, 0.0019841264002025127, 0.002082727150991559, 0.009469546377658844, 0.010749154724180698, 0.020741114392876625, 0.003959784284234047, 0.0022910877596586943, 0.008122682571411133, 0.0323147252202034, 0.012104026041924953, 0.0062302518635988235, 0.012823410332202911, 0.013441529124975204, 0.010644093155860901, 0.004347367212176323, 0.02191949635744095, 0.006058281287550926, 0.007096577435731888, 0.0031362702138721943, 0.011185604147613049, 0.006138128228485584, 0.005076500121504068, 0.017876887694001198, 0.0052444105967879295, 0.005625652614980936, 0.006518635433167219, 0.008317560888826847, 0.008304212242364883, 0.031129982322454453, 0.06091868504881859, 0.008311396464705467, 0.002119762357324362, 0.010541860945522785, 0.038440875709056854, 0.016574585810303688, 0.020577138289809227, 0.02095293626189232, 0.00949878990650177, 0.015949157997965813, 0.01798282563686371, 0.022527435794472694, 0.010018511675298214, 0.014718237332999706, 0.021683143451809883, 0.013465998694300652, 0.008396903052926064, 0.024176329374313354, 0.0819828137755394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003152797231450677, 0.00374571792781353, 0.01177328173071146, 0.0004913164884783328, 0.0035942913964390755, 0.004015421960502863, 0.01960745081305504, 0.0017898883670568466, 0.005152128636837006, 0.0021640369668602943, 0.0011304095387458801, 0.0009532984113320708, 0.00223619700409472, 0.005363886710256338, 0.004763124044984579, 0.007315793074667454, 0.0022834278643131256, 0.0005504767177626491, 0.006769617088139057, 0.003080988535657525, 0.0013087369734421372, 0.002187276491895318, 0.0018457494443282485, 0.002122972160577774, 0.0023010901641100645, 0.012336798012256622, 0.0003507323272060603, 0.0021665284875780344, 0.0020782938227057457, 0.0033886171877384186, 0.0004903573426418006, 0.00586635572835803, 0.003450490767136216, 0.06382138282060623, 0.001971185440197587, 0.002074272371828556, 0.0005310283740982413, 0.007098284084349871, 0.01065222080796957, 0.0010761957382783294, 0.00291775306686759, 0.002507243538275361, 0.012283134274184704, 0.004186444450169802, 0.0011408459395170212, 0.0011489962926134467, 0.0035782349295914173, 0.00425037881359458, 0.0017111636698246002, 0.03643609955906868, 0.008321400731801987, 0.0028225723654031754, 0.0035500654485076666, 0.0044798352755606174, 0.008462629280984402, 0.003085705917328596, 0.005786282476037741, 0.001290920190513134, 0.0010672628413885832, 0.008936233818531036, 0.001821622485294938, 0.0033112354576587677, 0.00467552337795496, 0.008105325512588024, 0.001967506017535925, 0.0009947001235559583, 0.012373383156955242, 0.07440509647130966, 0.02099176123738289, 0.018366092815995216, 0.047044288367033005, 0.01438690721988678, 0.01720212772488594, 0.02734551392495632, 0.022447913885116577, 0.021051505580544472, 0.03875427320599556, 0.07691726088523865, 0.020412325859069824, 0.0131765678524971, 0.029562467709183693, 0.05327940732240677, 0.13639192283153534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02993088774383068, 0.003086199751123786, 0.0072857970371842384, 0.0001723653549561277, 0.0016376422718167305, 0.007856205105781555, 0.016911689192056656, 0.000703939760569483, 0.0038449899293482304, 0.005033923778682947, 0.001046793069690466, 0.009686860255897045, 0.003431483404710889, 0.0015050213551148772, 0.0015408933395519853, 0.003973534796386957, 0.019624853506684303, 0.0035169273614883423, 0.004272752907127142, 0.007117208559066057, 0.0032575277145951986, 0.006470121908932924, 0.0062393806874752045, 0.007789993193000555, 0.003142882836982608, 0.005481621716171503, 0.00033973492099903524, 0.003269004402682185, 0.001974930986762047, 0.01387130469083786, 0.0007226454908959568, 0.011876789852976799, 0.03264700248837471, 0.031348079442977905, 0.0031963668297976255, 0.0035614799708127975, 0.004356855060905218, 0.005102782975882292, 0.019917942583560944, 0.008705715648829937, 0.003514577867463231, 0.0017558716936036944, 0.009902821853756905, 0.007753707468509674, 0.0020869113504886627, 0.005625235382467508, 0.013901720754802227, 0.00820481963455677, 0.001038083923049271, 0.017940759658813477, 0.00821663998067379, 0.0024757396895438433, 0.0015595469158142805, 0.012738642282783985, 0.012931487523019314, 0.005838965065777302, 0.021189255639910698, 0.002683943137526512, 0.0017148505430668592, 0.005970546044409275, 0.005936037749052048, 0.009105557575821877, 0.012225395999848843, 0.012081881053745747, 0.008676763623952866, 0.0003380212583579123, 0.007912777364253998, 0.0441204234957695, 0.010965594090521336, 0.015098389238119125, 0.030129779130220413, 0.010842138901352882, 0.012803575955331326, 0.0270078144967556, 0.01688055507838726, 0.016797367483377457, 0.014754841104149818, 0.025540517643094063, 0.01803828775882721, 0.007889564149081707, 0.018913310021162033, 0.08390111476182938, 0.08637399226427078, 0.051170188933610916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008286654949188232, 0.004602053202688694, 0.005597625393420458, 0.0009636828326620162, 0.006942344829440117, 0.0038937947247177362, 0.003613820066675544, 0.002228459343314171, 0.016021685674786568, 0.003693085163831711, 0.005375799722969532, 0.002309616655111313, 0.0035748297814279795, 0.005129625555127859, 0.0008446270949207246, 0.009370687417685986, 0.0013954113237559795, 0.0008873176411725581, 0.037915028631687164, 0.006835010834038258, 0.003703066846355796, 0.0020129012409597635, 0.00408124690875411, 0.0010027865646407008, 0.00038478444912470877, 0.00979423988610506, 0.0006909234798513353, 0.0026828099507838488, 0.002931507769972086, 0.00322240823879838, 0.00030916737159714103, 0.005285243969410658, 0.004622051026672125, 0.026430657133460045, 0.0019709926564246416, 0.00457107275724411, 0.0019407030194997787, 0.01666894555091858, 0.013202005997300148, 0.0010685684392228723, 0.00218393886461854, 0.0010491174180060625, 0.003942569717764854, 0.0012391250347718596, 0.0019085779786109924, 0.00485585443675518, 0.005446974653750658, 0.041271939873695374, 0.0021103201434016228, 0.004466923885047436, 0.01721165142953396, 0.0021058886777609587, 0.008097861893475056, 0.008967549540102482, 0.0021970216184854507, 0.027934839949011803, 0.00527217285707593, 0.00302206096239388, 0.001533751841634512, 0.002533094258978963, 0.0018270732834935188, 0.0029041513334959745, 0.001974148442968726, 0.009388966485857964, 0.002618915867060423, 0.000484233140014112, 0.006130747962743044, 0.07117356359958649, 0.029193097725510597, 0.01137327030301094, 0.07128261774778366, 0.02951931208372116, 0.02415439859032631, 0.011074433103203773, 0.030195094645023346, 0.010250390507280827, 0.02511969767510891, 0.043231669813394547, 0.03505953401327133, 0.011977028101682663, 0.01692081429064274, 0.046746231615543365, 0.05369967222213745, 0.018478751182556152, 0.05181364342570305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008824160322546959, 0.01197933778166771, 0.0071373446844518185, 0.0011998643167316914, 0.005668667610734701, 0.0030270779971033335, 0.00524688558652997, 0.00191137392539531, 0.016089482232928276, 0.0031797976698726416, 0.005570841487497091, 0.004479371011257172, 0.013122010044753551, 0.015479867346584797, 0.0025754463858902454, 0.0056311762891709805, 0.00343279424123466, 0.003349138190969825, 0.01483650878071785, 0.011724306270480156, 0.011040491983294487, 0.0034214735496789217, 0.012301767244935036, 0.004167903680354357, 0.00341020617634058, 0.004755079280585051, 0.0008007475989870727, 0.010978235863149166, 0.004507656209170818, 0.006866979878395796, 0.0015656877076253295, 0.0056492239236831665, 0.009559971280395985, 0.025422196835279465, 0.005410750862210989, 0.004354928154498339, 0.0037380412686616182, 0.005593801848590374, 0.007163438014686108, 0.0032932257745414972, 0.008389079011976719, 0.008047543466091156, 0.004113064147531986, 0.0038958953227847815, 0.0034745086450129747, 0.010722624137997627, 0.003811812726780772, 0.033109407871961594, 0.0029761656187474728, 0.011300160549581051, 0.012303201481699944, 0.00763534614816308, 0.0048055946826934814, 0.009737417101860046, 0.004821535665541887, 0.016091402620077133, 0.01440056785941124, 0.005954729858785868, 0.004008874762803316, 0.0038169000763446093, 0.001732683856971562, 0.00551856542006135, 0.01068927813321352, 0.011471046134829521, 0.006404078099876642, 0.0013412643456831574, 0.00819999910891056, 0.047557346522808075, 0.017158817499876022, 0.015241441316902637, 0.02327626198530197, 0.021805301308631897, 0.009278892539441586, 0.011322610080242157, 0.0284942127764225, 0.017029913142323494, 0.04677051305770874, 0.03029146045446396, 0.017530081793665886, 0.012484623119235039, 0.01597370021045208, 0.04209353029727936, 0.06398745626211166, 0.025724263861775398, 0.023578347638249397, 0.03316129744052887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008831118233501911, 0.020191533491015434, 0.0069507332518696785, 0.0021216552704572678, 0.003825470572337508, 0.0032174631487578154, 0.014129512943327427, 0.0014948465395718813, 0.008784059435129166, 0.0061065927147865295, 0.010784165933728218, 0.003921066876500845, 0.01501696277409792, 0.013658326119184494, 0.004318223800510168, 0.0025544820819050074, 0.00932993646711111, 0.007086665369570255, 0.018435820937156677, 0.005125777795910835, 0.006963285617530346, 0.005189368035644293, 0.008671179413795471, 0.0033705725800246, 0.007836742326617241, 0.006400765851140022, 0.0015218418557196856, 0.013338485732674599, 0.006259968038648367, 0.003403043607249856, 0.004202661570161581, 0.007898516021668911, 0.011559983715415001, 0.026611201465129852, 0.011616194620728493, 0.005385906435549259, 0.012975049205124378, 0.006658343598246574, 0.00371818826533854, 0.004656931385397911, 0.015117495320737362, 0.01083210576325655, 0.008123604580760002, 0.009788323193788528, 0.008677131496369839, 0.008840878494083881, 0.0062927664257586, 0.008916482329368591, 0.004989416338503361, 0.01589129865169525, 0.008382434956729412, 0.018156737089157104, 0.003091769525781274, 0.011581696569919586, 0.008658099919557571, 0.02729813940823078, 0.014205318875610828, 0.007370909210294485, 0.009663923643529415, 0.0044797929003834724, 0.003193686017766595, 0.009248706512153149, 0.022735614329576492, 0.011338135227560997, 0.004726376384496689, 0.0020907395519316196, 0.011247142218053341, 0.029488209635019302, 0.018589403480291367, 0.014260586351156235, 0.028221311047673225, 0.014804240316152573, 0.01246730238199234, 0.013057004660367966, 0.023312417790293694, 0.0225329902023077, 0.03157162666320801, 0.020924028009176254, 0.0276055708527565, 0.014058335684239864, 0.011088288389146328, 0.02257572114467621, 0.021944796666502953, 0.018271280452609062, 0.01815052703022957, 0.01659184880554676, 0.02142317034304142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008237496949732304, 0.0063363127410411835, 0.010477322153747082, 0.0009592252317816019, 0.0047866906970739365, 0.0027708569541573524, 0.023349693045020103, 0.0037505938671529293, 0.004895936697721481, 0.01010395772755146, 0.0030522106681019068, 0.003250570734962821, 0.0031695463694632053, 0.007656646892428398, 0.004871082026511431, 0.0018247361294925213, 0.0026584086008369923, 0.0020621761213988066, 0.016843562945723534, 0.005445614457130432, 0.002039966406300664, 0.005210974253714085, 0.0019132158486172557, 0.0026822786312550306, 0.0014030999736860394, 0.006813098676502705, 0.0051177931018173695, 0.01153127383440733, 0.0034035725984722376, 0.005639759823679924, 0.0006051887175999582, 0.010296379216015339, 0.012953532859683037, 0.028363659977912903, 0.007388823200017214, 0.00823664665222168, 0.009236717596650124, 0.008501918986439705, 0.007000545971095562, 0.0057853818871080875, 0.004661434795707464, 0.0030632854904979467, 0.01664135418832302, 0.002593503799289465, 0.00526445871219039, 0.0028203546535223722, 0.010254639200866222, 0.017886284738779068, 0.001881587551906705, 0.005381907802075148, 0.005910606123507023, 0.009229949675500393, 0.003990324214100838, 0.009187842719256878, 0.0024790489114820957, 0.015130575746297836, 0.009886547923088074, 0.010133749805390835, 0.003010261571034789, 0.005518083926290274, 0.0034356280229985714, 0.004547039046883583, 0.017919935286045074, 0.013719586655497551, 0.007038600277155638, 0.0005161723820492625, 0.009236852638423443, 0.05803338438272476, 0.012878607958555222, 0.01746899075806141, 0.055789656937122345, 0.01772206835448742, 0.012193586677312851, 0.010670608840882778, 0.01489371620118618, 0.011809070594608784, 0.013261973857879639, 0.039797987788915634, 0.046610038727521896, 0.021292753517627716, 0.022368038073182106, 0.02851993404328823, 0.01955580711364746, 0.022467967122793198, 0.04009991139173508, 0.00775265134871006, 0.013173512183129787, 0.041673675179481506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013940162025392056, 0.003256994066759944, 0.009155270643532276, 0.0009442666196264327, 0.0019376801792532206, 0.0019038052996620536, 0.006268735975027084, 0.001976722851395607, 0.00764367775991559, 0.006400293204933405, 0.0012836422538384795, 0.00147979985922575, 0.0014385401736944914, 0.002852006582543254, 0.0016424020286649466, 0.0024873721413314342, 0.0018000915879383683, 0.0019444358767941594, 0.012553447857499123, 0.002719723619520664, 0.0018827395979315042, 0.005550742149353027, 0.00139328942168504, 0.0015324606793001294, 0.000735244422685355, 0.004806918557733297, 0.0007253554067574441, 0.002717355266213417, 0.0012419591657817364, 0.0027246575336903334, 0.0003728274896275252, 0.008867468684911728, 0.009110670536756516, 0.04301901534199715, 0.002780443523079157, 0.00523087102919817, 0.0033829130697995424, 0.007945120334625244, 0.007189507596194744, 0.00106986821629107, 0.0022930086124688387, 0.0007938228081911802, 0.004617602098733187, 0.0010906028328463435, 0.002312195021659136, 0.002188896993175149, 0.015696248039603233, 0.012290582060813904, 0.0006031968514434993, 0.004636529367417097, 0.0068316408433020115, 0.002303031273186207, 0.0027166642248630524, 0.004806989803910255, 0.0020081419497728348, 0.009688044898211956, 0.00629796739667654, 0.002263501984998584, 0.0013726529432460666, 0.0031853793188929558, 0.002748378785327077, 0.002814499195665121, 0.004091032315045595, 0.019558481872081757, 0.0012163263745605946, 0.00039528991328552365, 0.005972607526928186, 0.07555273175239563, 0.03095182776451111, 0.020879769697785378, 0.08954928815364838, 0.02159750461578369, 0.019454872235655785, 0.017015432938933372, 0.03090563602745533, 0.02149413898587227, 0.021354982629418373, 0.037353165447711945, 0.029238371178507805, 0.012253069318830967, 0.019902298226952553, 0.047314465045928955, 0.04688483104109764, 0.02684076502919197, 0.028307143598794937, 0.011382597498595715, 0.010982946492731571, 0.022469306364655495, 0.03761305287480354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002988272812217474, 0.007019414100795984, 0.013605955988168716, 0.0011213248362764716, 0.0026533405762165785, 0.0019165347330272198, 0.008058491162955761, 0.00916146021336317, 0.004025629255920649, 0.0022394033148884773, 0.0010046043898910284, 0.0032089343294501305, 0.0024467245675623417, 0.0031083303038030863, 0.007521526888012886, 0.007246972061693668, 0.0023580712731927633, 0.0031361058354377747, 0.00799519382417202, 0.0052657658234238625, 0.0006831603241153061, 0.012999151833355427, 0.0026118725072592497, 0.001759365783073008, 0.005594333168119192, 0.0036906758323311806, 0.0012273945612832904, 0.0026562109123915434, 0.0018478045240044594, 0.00838969461619854, 0.001969890668988228, 0.00945093110203743, 0.00474828016012907, 0.03902444243431091, 0.0018646273529157043, 0.0019394733244553208, 0.00564051466062665, 0.0033667979296296835, 0.004474603105336428, 0.0019469752442091703, 0.0027828523889184, 0.006852877326309681, 0.0028071999549865723, 0.0027202314231544733, 0.0009748282027430832, 0.0009385650628246367, 0.01150800846517086, 0.013680055737495422, 0.00109843909740448, 0.009503747336566448, 0.004039984196424484, 0.0023327996022999287, 0.002045632340013981, 0.0030406254809349775, 0.002581946784630418, 0.0026893727481365204, 0.00450439378619194, 0.003397543216124177, 0.001919018803164363, 0.0031948788091540337, 0.0045711868442595005, 0.004710671957582235, 0.004867651965469122, 0.015153631567955017, 0.002550154458731413, 0.0013062163488939404, 0.007229342125356197, 0.059759389609098434, 0.020061582326889038, 0.0169443991035223, 0.03617551550269127, 0.015782449394464493, 0.008370090276002884, 0.015130027197301388, 0.020088428631424904, 0.009727240540087223, 0.04541655629873276, 0.03205832839012146, 0.0422387570142746, 0.007406431250274181, 0.030012937262654305, 0.06112006679177284, 0.04357539117336273, 0.058064959943294525, 0.02857106365263462, 0.023379623889923096, 0.013276688754558563, 0.017534010112285614, 0.020446855574846268, 0.03988908231258392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012018296867609024, 0.009563438594341278, 0.010477294214069843, 0.0006530163809657097, 0.0014888953883200884, 0.0015250025317072868, 0.004999928176403046, 0.001797412638552487, 0.009237273596227169, 0.001764923450537026, 0.004013684578239918, 0.0018285689875483513, 0.0019150851294398308, 0.00519194919615984, 0.0008675782009959221, 0.008570392616093159, 0.001728350529447198, 0.0013195069041103125, 0.018580349162220955, 0.0019964310340583324, 0.001373096602037549, 0.0044665588065981865, 0.003078728448599577, 0.0011948029277846217, 0.005404836498200893, 0.0045629278756678104, 0.00010255363304167986, 0.0030230858828872442, 0.0019727570470422506, 0.00263959146104753, 0.0008558064582757652, 0.013911987654864788, 0.005857816431671381, 0.0339515246450901, 0.0013862416381016374, 0.0022234362550079823, 0.001972310710698366, 0.010665231384336948, 0.011021123267710209, 0.001333630527369678, 0.0014244464691728354, 0.0034438264556229115, 0.002127007581293583, 0.0019257740350440145, 0.0019463514909148216, 0.0036192918196320534, 0.004227044060826302, 0.005396001040935516, 0.000933565606828779, 0.011839470826089382, 0.007581707090139389, 0.003835977055132389, 0.001903718919493258, 0.004126119427382946, 0.003228183835744858, 0.010396462865173817, 0.004705367144197226, 0.0008455868228338659, 0.0015982354525476694, 0.0018287529237568378, 0.0017594423843547702, 0.008774738758802414, 0.007101874798536301, 0.018084945157170296, 0.0011892003240063787, 0.00030308871646411717, 0.00434870645403862, 0.05877756327390671, 0.028314072638750076, 0.013449355028569698, 0.04194685071706772, 0.01625863090157509, 0.016018738970160484, 0.01703314483165741, 0.049761202186346054, 0.012250336818397045, 0.03399045765399933, 0.04044045880436897, 0.020528746768832207, 0.007408109959214926, 0.018890520557761192, 0.051487985998392105, 0.039023518562316895, 0.03929813578724861, 0.030938269570469856, 0.017341334372758865, 0.015325555577874184, 0.012009715661406517, 0.021513942629098892, 0.011913163587450981, 0.057049836963415146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010182786732912064, 0.006554604507982731, 0.01841459795832634, 0.0011600004509091377, 0.010535343550145626, 0.0033367867581546307, 0.0132846524938941, 0.0023727526422590017, 0.014690758660435677, 0.003450813703238964, 0.0041016023606061935, 0.0011563036823645234, 0.0018250052817165852, 0.02260032296180725, 0.008749290369451046, 0.005073136184364557, 0.004232392646372318, 0.0013899407349526882, 0.012763620354235172, 0.00257437233813107, 0.0027008738834410906, 0.003702527144923806, 0.0021081450395286083, 0.002421122742816806, 0.004855786915868521, 0.014158661477267742, 0.0005398296052590013, 0.010090104304254055, 0.002328314818441868, 0.005418227985501289, 0.0019382521277293563, 0.010184497572481632, 0.006408573593944311, 0.02616860345005989, 0.0014910262543708086, 0.006558395456522703, 0.0013573599280789495, 0.013557733036577702, 0.015062827616930008, 0.002338947495445609, 0.0016897893510758877, 0.0031086623203009367, 0.01216500997543335, 0.0062967706471681595, 0.00739936251193285, 0.003327074460685253, 0.00626428471878171, 0.004110386595129967, 0.0012684043031185865, 0.02216474711894989, 0.011139865964651108, 0.011183674447238445, 0.012591724283993244, 0.005637709982693195, 0.003868378698825836, 0.006820834241807461, 0.008309461176395416, 0.0021018399856984615, 0.004506372381001711, 0.008602939546108246, 0.002493235981091857, 0.003396177664399147, 0.016048382967710495, 0.017475850880146027, 0.007273356895893812, 0.00137828360311687, 0.005107042845338583, 0.06947094947099686, 0.012844229117035866, 0.015302930027246475, 0.023719733580946922, 0.01146925799548626, 0.011731560342013836, 0.009030105546116829, 0.01804737187922001, 0.01536355260759592, 0.019597860053181648, 0.027514604851603508, 0.014993689954280853, 0.011282158084213734, 0.021632665768265724, 0.03286857530474663, 0.039147768169641495, 0.016825905069708824, 0.01688477396965027, 0.007852879352867603, 0.010898929089307785, 0.016052814200520515, 0.013254571706056595, 0.005069224629551172, 0.050514474511146545, 0.03106095641851425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009138007648289204, 0.018785441294312477, 0.010001695714890957, 0.002221622969955206, 0.001694618840701878, 0.001742994412779808, 0.010022852569818497, 0.0025479523465037346, 0.004088501445949078, 0.005250634625554085, 0.009392719715833664, 0.003220852930098772, 0.01332490798085928, 0.0031050723046064377, 0.0011121293064206839, 0.002047987887635827, 0.006322847679257393, 0.006944894324988127, 0.014685438945889473, 0.003461501793935895, 0.007858365774154663, 0.007853365503251553, 0.0059454720467329025, 0.0038917437195777893, 0.006844629533588886, 0.004256000276654959, 0.0010294447420164943, 0.0070388116873800755, 0.0043179928325116634, 0.004079905338585377, 0.0034084722865372896, 0.040101684629917145, 0.007145908195525408, 0.01954578049480915, 0.009532839059829712, 0.006209350656718016, 0.011456320993602276, 0.007179862819612026, 0.005708109121769667, 0.002993110567331314, 0.017050785943865776, 0.00979988370090723, 0.00532453553751111, 0.006686185020953417, 0.006837597582489252, 0.0188298262655735, 0.006872983183711767, 0.014610415324568748, 0.002669085282832384, 0.0177439134567976, 0.006815499160438776, 0.005539583042263985, 0.0009471254306845367, 0.016388457268476486, 0.007281171623617411, 0.018067840486764908, 0.006937264930456877, 0.004930682945996523, 0.006642636377364397, 0.004512393847107887, 0.006327081471681595, 0.027832232415676117, 0.018232451751828194, 0.029357310384511948, 0.00301225483417511, 0.0007757528219372034, 0.00939465407282114, 0.018850184977054596, 0.016542352735996246, 0.0076689524576067924, 0.02685260772705078, 0.008119815029203892, 0.014122681692242622, 0.02344324067234993, 0.018873412162065506, 0.009865817613899708, 0.013829036615788937, 0.019477766007184982, 0.026989193633198738, 0.009735443629324436, 0.012140554375946522, 0.01913619600236416, 0.013604016043245792, 0.029027093201875687, 0.018859203904867172, 0.010167762637138367, 0.009755571372807026, 0.009934503585100174, 0.017383648082613945, 0.013662748970091343, 0.022842414677143097, 0.016179390251636505, 0.01800689287483692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006128653883934021, 0.02048357017338276, 0.01800411194562912, 0.001111894496716559, 0.0034054003190249205, 0.002478472888469696, 0.027983900159597397, 0.0021207984536886215, 0.003864666912704706, 0.006538932211697102, 0.007384935859590769, 0.006379679776728153, 0.007649846374988556, 0.007591411471366882, 0.005404837429523468, 0.0018602462951093912, 0.007981826551258564, 0.0028939242474734783, 0.0063986508175730705, 0.0029161979909986258, 0.003145323833450675, 0.011294268071651459, 0.0066638910211622715, 0.002037471393123269, 0.0036101480945944786, 0.009255371056497097, 0.0010573472827672958, 0.0038961891550570726, 0.003192008938640356, 0.0060200984589755535, 0.0013334365794435143, 0.00657471502199769, 0.014518169686198235, 0.022206945344805717, 0.011126267723739147, 0.0023812679573893547, 0.008920750580728054, 0.008865573443472385, 0.006410964764654636, 0.010794001631438732, 0.008555673062801361, 0.005603428464382887, 0.012006832286715508, 0.008432375267148018, 0.012260227464139462, 0.0047927964478731155, 0.008326857350766659, 0.005092051345854998, 0.0019182077376171947, 0.03240779787302017, 0.007034146226942539, 0.006594283506274223, 0.0020718201994895935, 0.010166371241211891, 0.007322679273784161, 0.0130683071911335, 0.021338975057005882, 0.005475583020597696, 0.0037066303193569183, 0.013429106213152409, 0.007259459234774113, 0.006046234164386988, 0.021120451390743256, 0.007013384252786636, 0.005856131669133902, 0.0012282765237614512, 0.006724356207996607, 0.02471034973859787, 0.00801772903650999, 0.009023157879710197, 0.023727284744381905, 0.005587392020970583, 0.008243470452725887, 0.01301814615726471, 0.013016672804951668, 0.010800673626363277, 0.010242097079753876, 0.02654043212532997, 0.01742376759648323, 0.009607253596186638, 0.02540873922407627, 0.016080016270279884, 0.03218739479780197, 0.0255117304623127, 0.02603175677359104, 0.008234121836721897, 0.010169398970901966, 0.009304159320890903, 0.011251736432313919, 0.012741311453282833, 0.022055886685848236, 0.029224544763565063, 0.01864469051361084, 0.03645746782422066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002338036196306348, 0.006073698867112398, 0.01776321418583393, 0.002363752806559205, 0.006126293446868658, 0.00168284319806844, 0.01154328603297472, 0.0028719741385430098, 0.016371604055166245, 0.013835174031555653, 0.005274398718029261, 0.004715058021247387, 0.0026728976517915726, 0.0070222835056483746, 0.005282459314912558, 0.012447032146155834, 0.006055844482034445, 0.00863116979598999, 0.005271618254482746, 0.008507110178470612, 0.004899380262941122, 0.004800938069820404, 0.005553096998482943, 0.0016268835170194507, 0.0030914992094039917, 0.00775036821141839, 0.002276164945214987, 0.004981428384780884, 0.0030489799100905657, 0.003648885292932391, 0.0027840794064104557, 0.0057358574122190475, 0.015226063318550587, 0.023751169443130493, 0.004850117955356836, 0.0022188653238117695, 0.006277595646679401, 0.009094796143472195, 0.03361167386174202, 0.004676100332289934, 0.001507714856415987, 0.0017646821215748787, 0.009820831939578056, 0.00687251565977931, 0.006894891615957022, 0.0030753694009035826, 0.007619363721460104, 0.012494533322751522, 0.0017097108066082, 0.008410832844674587, 0.005409253761172295, 0.003614063374698162, 0.005020427517592907, 0.006234290543943644, 0.004575940780341625, 0.0034762572031468153, 0.026976382359862328, 0.004788403399288654, 0.005984551273286343, 0.007533458527177572, 0.004314274061471224, 0.004269228782504797, 0.010877099819481373, 0.008777657523751259, 0.002862133551388979, 0.004439415410161018, 0.007402805611491203, 0.03536485135555267, 0.020883306860923767, 0.0098258713260293, 0.031971871852874756, 0.014297840185463428, 0.020041894167661667, 0.009599636308848858, 0.016102071851491928, 0.014560993760824203, 0.019268309697508812, 0.03086993843317032, 0.014499746263027191, 0.009144891053438187, 0.01682102307677269, 0.02240522764623165, 0.029873313382267952, 0.021927360445261, 0.019147289916872978, 0.007323793601244688, 0.010836060158908367, 0.015775060281157494, 0.015007717534899712, 0.010625963099300861, 0.018981119617819786, 0.020673824474215508, 0.019128812476992607, 0.03347376734018326, 0.018088603392243385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05383585765957832, 0.0031450644601136446, 0.005894867703318596, 0.0005805785767734051, 0.00152753631118685, 0.002493607811629772, 0.005294302478432655, 0.0014865535777062178, 0.0050391536206007, 0.0049310484901070595, 0.0012957265134900808, 0.0025351590011268854, 0.0012426760513335466, 0.002123442478477955, 0.0016330830985680223, 0.00252308277413249, 0.0030116131529212, 0.0021463241428136826, 0.010129590518772602, 0.0021779355593025684, 0.0028641510289162397, 0.004323584493249655, 0.0013570074224844575, 0.0021196373272687197, 0.0015737005742266774, 0.008808288723230362, 0.00046127403038553894, 0.0038262137677520514, 0.0021014069207012653, 0.0049488740041852, 0.0012359004467725754, 0.012051220051944256, 0.005186633672565222, 0.025589752942323685, 0.0016675465740263462, 0.00497229490429163, 0.002622272353619337, 0.004245970863848925, 0.009521612897515297, 0.0015922044403851032, 0.0017359716584905982, 0.0013729110360145569, 0.009109810926020145, 0.002457684138789773, 0.0022885221987962723, 0.004759047646075487, 0.0197182297706604, 0.008106605149805546, 0.0015118828741833568, 0.0097503662109375, 0.006320707965642214, 0.0031164607498794794, 0.002331528812646866, 0.007858465425670147, 0.003161918604746461, 0.004605639260262251, 0.0031733487267047167, 0.0012570940889418125, 0.0020754397846758366, 0.0022110361605882645, 0.00482774106785655, 0.0062815654091537, 0.0043379757553339005, 0.012918241322040558, 0.0026467640418559313, 0.0008343625231646001, 0.005936818663030863, 0.05311637371778488, 0.024716684594750404, 0.013451886363327503, 0.05368584021925926, 0.010196845047175884, 0.020832980051636696, 0.017489615827798843, 0.02352558635175228, 0.009255707263946533, 0.011897113174200058, 0.028767265379428864, 0.031745582818984985, 0.007442100904881954, 0.014476843178272247, 0.0758364200592041, 0.037198930978775024, 0.03332802653312683, 0.011283408850431442, 0.01019833330065012, 0.006707701366394758, 0.009036875329911709, 0.012622230686247349, 0.011204777285456657, 0.02901334874331951, 0.01092575490474701, 0.019843224436044693, 0.03507394716143608, 0.013159255497157574, 0.015144390985369682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004343904554843903, 0.009171837940812111, 0.0018936902051791549, 0.0006410106434486806, 0.0012231901055201888, 0.008345677517354488, 0.019536612555384636, 0.0009467448689974844, 0.0017639101715758443, 0.001428551273420453, 0.0015447103651240468, 0.0010390940587967634, 0.003587061306461692, 0.003714687190949917, 0.006392753217369318, 0.005403133574873209, 0.0014333173166960478, 0.001467105932533741, 0.004412600304931402, 0.0008765374659560621, 0.000529928773175925, 0.0007523820386268198, 0.0008262670016847551, 0.0033385748974978924, 0.0003591805580072105, 0.001490144175477326, 7.376068970188498e-05, 0.0010015370789915323, 0.0006168782128952444, 0.010123060084879398, 0.00030130590312182903, 0.00752854673191905, 0.0012026069452986121, 0.03985631465911865, 0.0018143546767532825, 0.0031602345407009125, 0.001351411221548915, 0.0010715764947235584, 0.0032450887374579906, 0.0005903588607907295, 0.0021806303411722183, 0.008352624252438545, 0.006326563190668821, 0.0014870564918965101, 0.001451420015655458, 0.0011232553515583277, 0.002389393048360944, 0.007112280931323767, 0.0005833348841406405, 0.017812054604291916, 0.004497488494962454, 0.0029414608143270016, 0.000840329157654196, 0.0030497070401906967, 0.005818704608827829, 0.003689575707539916, 0.001952191349118948, 0.0021734063047915697, 0.00032161109265871346, 0.0024901253636926413, 0.00030678848270326853, 0.000984253827482462, 0.0009882502490654588, 0.016232674941420555, 0.00493616471067071, 0.00021536852000281215, 0.0028318078257143497, 0.03620053827762604, 0.004847952164709568, 0.0075509557500481606, 0.014137191697955132, 0.007349909748882055, 0.004857076797634363, 0.023512152954936028, 0.02735414355993271, 0.007402022834867239, 0.032353680580854416, 0.03926553949713707, 0.01625608652830124, 0.00783710926771164, 0.016707399860024452, 0.07914989441633224, 0.058503083884716034, 0.024933405220508575, 0.01791287586092949, 0.012705004774034023, 0.006943528074771166, 0.010858453810214996, 0.008161921985447407, 0.0070028952322900295, 0.05203370377421379, 0.007505370769649744, 0.019752878695726395, 0.033642254769802094, 0.0035389766562730074, 0.017017018049955368, 0.13321882486343384, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008798281662166119, 0.007053985260426998, 0.005937120411545038, 0.0012146191438660026, 0.003875297261402011, 0.0031094790901988745, 0.012376007623970509, 0.002079891739413142, 0.005384140182286501, 0.004173790570348501, 0.007427290081977844, 0.0032228464260697365, 0.0028978059999644756, 0.007333225104957819, 0.004387577995657921, 0.002972896210849285, 0.003399000270292163, 0.0006085410132072866, 0.01295939739793539, 0.0030917231924831867, 0.003294108435511589, 0.004285839851945639, 0.00717843696475029, 0.001489758607931435, 0.0014794472372159362, 0.009785677306354046, 0.0005553943919949234, 0.0037780809216201305, 0.002101330319419503, 0.005264449864625931, 0.0007642717100679874, 0.005086835008114576, 0.012760397978127003, 0.02261028252542019, 0.003499815706163645, 0.004497521556913853, 0.002150732558220625, 0.005887817125767469, 0.007935295812785625, 0.0033209531102329493, 0.0032635352108627558, 0.002701888792216778, 0.007696313317865133, 0.0034349418710917234, 0.007205240894109011, 0.004169940482825041, 0.004652278497815132, 0.006990879308432341, 0.001693733618594706, 0.012649660930037498, 0.006232601124793291, 0.004384129773825407, 0.0054937307722866535, 0.010619896464049816, 0.0031557674519717693, 0.016857050359249115, 0.010554865002632141, 0.0026989916805177927, 0.003219406818971038, 0.00956697203218937, 0.002484745578840375, 0.0022274088114500046, 0.00657079229131341, 0.00713162450119853, 0.005454284138977528, 0.0009644482634030282, 0.004638862330466509, 0.04537992924451828, 0.013077369891107082, 0.015229209326207638, 0.028103601187467575, 0.019231213256716728, 0.00885385274887085, 0.012543580494821072, 0.0269054863601923, 0.013254237361252308, 0.019698496907949448, 0.024114158004522324, 0.016431249678134918, 0.00875021144747734, 0.020902132615447044, 0.026793142780661583, 0.03994109854102135, 0.020045217126607895, 0.03188587725162506, 0.010397718288004398, 0.011243495158851147, 0.01138109341263771, 0.014755332842469215, 0.007635806687176228, 0.025425387546420097, 0.02627451717853546, 0.01543508656322956, 0.03757423162460327, 0.01227507647126913, 0.013770896941423416, 0.021686309948563576, 0.03426160663366318, 0.0, 0.0, 0.0, 0.0], [0.02591017261147499, 0.002146919956430793, 0.002436487702652812, 0.0008517084643244743, 0.0011331241112202406, 0.0020409394055604935, 0.008823494426906109, 0.001202788669615984, 0.00406448170542717, 0.010442464612424374, 0.0009090678649954498, 0.0013159216614440084, 0.002580577740445733, 0.002083727391436696, 0.0019330703653395176, 0.0020440183579921722, 0.003779462305828929, 0.002052337396889925, 0.004140145145356655, 0.0029635995160788298, 0.0024989512749016285, 0.005909666419029236, 0.0034489119425415993, 0.0034081002231687307, 0.0034333786461502314, 0.005418651737272739, 0.0008752393769100308, 0.005364572629332542, 0.0026836071629077196, 0.005566288251429796, 0.0007590933819301426, 0.015452094376087189, 0.009809144772589207, 0.028604459017515182, 0.0056557501666247845, 0.005884384736418724, 0.0017638588324189186, 0.002207079902291298, 0.007555136922746897, 0.0012186113744974136, 0.006769201718270779, 0.001520428922958672, 0.010161458514630795, 0.002190484432503581, 0.0021865428425371647, 0.003947444260120392, 0.01783866621553898, 0.008242381736636162, 0.001340510556474328, 0.008519146591424942, 0.003527237568050623, 0.004407043568789959, 0.0013127145357429981, 0.014750570990145206, 0.004806777462363243, 0.003466295311227441, 0.0034108348190784454, 0.002632463350892067, 0.0019625599961727858, 0.0025947466492652893, 0.0026942379772663116, 0.013091053813695908, 0.008120805956423283, 0.020387640222907066, 0.004934101831167936, 0.0013492319267243147, 0.008099175058305264, 0.030103154480457306, 0.015850255265831947, 0.01796458475291729, 0.03408690541982651, 0.01706838048994541, 0.022773589938879013, 0.018289482221007347, 0.014072226360440254, 0.017436793074011803, 0.016374388709664345, 0.015739431604743004, 0.025861581787467003, 0.004591299220919609, 0.011920122429728508, 0.048343103379011154, 0.04063959792256355, 0.021877259016036987, 0.015240976586937904, 0.006710972171276808, 0.009632408618927002, 0.00986635684967041, 0.01528248842805624, 0.006313332822173834, 0.018014684319496155, 0.014234342612326145, 0.0220204945653677, 0.026700953021645546, 0.009576239623129368, 0.019185980781912804, 0.023804256692528725, 0.024620193988084793, 0.041168928146362305, 0.0, 0.0, 0.0], [0.0060264370404183865, 0.008300862275063992, 0.008427996188402176, 0.0012741026002913713, 0.0027754257898777723, 0.0005216901190578938, 0.0033960267901420593, 0.0019189303275197744, 0.0042883348651230335, 0.0005214849370531738, 0.002898832783102989, 0.00029904823168180883, 0.0011393360327929258, 0.00737680122256279, 0.0008035927312448621, 0.0011859559454023838, 0.002014651196077466, 0.0004497612244449556, 0.008637131191790104, 0.0013104764511808753, 0.0017241711029782891, 0.0016476658638566732, 0.0014601439470425248, 0.00023109602625481784, 0.001381572219543159, 0.007230696268379688, 0.0002795755281113088, 0.002080685691908002, 0.0014009012375026941, 0.0016321983421221375, 0.000614454154856503, 0.02178688906133175, 0.0009212348377332091, 0.017366847023367882, 0.0004769104707520455, 0.0012777899391949177, 0.0011959281982854009, 0.008451693691313267, 0.0027038424741476774, 0.00018639843619894236, 0.0006096381112001836, 0.004218830727040768, 0.007025797851383686, 0.0033407374285161495, 0.001623194315470755, 0.00297301122918725, 0.0014855025801807642, 0.0077997674234211445, 0.0009534721029922366, 0.011643899604678154, 0.00633211899548769, 0.0037541501224040985, 0.004516163840889931, 0.005007152911275625, 0.0008511680644005537, 0.0033309420105069876, 0.000873528653755784, 0.0016031995182856917, 0.0009632776491343975, 0.0014877008507028222, 0.0011675970163196325, 0.00202557654120028, 0.0030735500622540712, 0.028780044987797737, 0.0010688514448702335, 0.00035710990778170526, 0.0036397636868059635, 0.05628832057118416, 0.02946644462645054, 0.007464407943189144, 0.03424633666872978, 0.00874226726591587, 0.01251389179378748, 0.012857218272984028, 0.030093049630522728, 0.015034117735922337, 0.03278517350554466, 0.027130722999572754, 0.014817839488387108, 0.004770262166857719, 0.019365713000297546, 0.055695194751024246, 0.022366348654031754, 0.027467507869005203, 0.014250119216740131, 0.009226429276168346, 0.005398666486144066, 0.01562890224158764, 0.01201731339097023, 0.011295422911643982, 0.030834903940558434, 0.019315261393785477, 0.00965599250048399, 0.031015669927001, 0.01720493473112583, 0.008379165083169937, 0.041683997958898544, 0.052288755774497986, 0.017531564459204674, 0.045044753700494766, 0.0, 0.0], [0.010717068798840046, 0.012690897099673748, 0.011295893229544163, 0.0005157377454452217, 0.0030465240124613047, 0.0008390304283238947, 0.01013383362442255, 0.0005310728447511792, 0.0033107902854681015, 0.0014110482297837734, 0.00219193147495389, 0.0029795649461448193, 0.003585450118407607, 0.00665403762832284, 0.001362055423669517, 0.0008427437860518694, 0.01150950975716114, 0.0012738322839140892, 0.006670528091490269, 0.002873968565836549, 0.002707824343815446, 0.0019231881015002728, 0.0030412855558097363, 0.0008900350658223033, 0.004177366383373737, 0.007020839489996433, 0.0003905962221324444, 0.004912177100777626, 0.001709081931039691, 0.0013425078941509128, 0.0008212741813622415, 0.005158351734280586, 0.004631326533854008, 0.01826762966811657, 0.0029804145451635122, 0.001781609607860446, 0.004462130833417177, 0.014876303263008595, 0.0018632207065820694, 0.004783988930284977, 0.005251327529549599, 0.0065290965139865875, 0.011167438700795174, 0.015976345166563988, 0.0030954433605074883, 0.004429271910339594, 0.002173619344830513, 0.005863560829311609, 0.001499383244663477, 0.012981820851564407, 0.010528268292546272, 0.008669943548738956, 0.005598645191639662, 0.005540697835385799, 0.003697039093822241, 0.010541792027652264, 0.0036151146050542593, 0.003244510618969798, 0.002186958910897374, 0.003733675926923752, 0.002526115393266082, 0.005830401089042425, 0.014995142817497253, 0.004767482168972492, 0.001744026318192482, 0.000526221061591059, 0.006961834151297808, 0.035974953323602676, 0.021804289892315865, 0.00799140240997076, 0.03103693760931492, 0.00745807122439146, 0.009807921014726162, 0.009485423564910889, 0.013179061003029346, 0.015856580808758736, 0.021098343655467033, 0.021622588858008385, 0.016019446775317192, 0.0063750045374035835, 0.01110963523387909, 0.026223447173833847, 0.024101439863443375, 0.02249424159526825, 0.008974917232990265, 0.00785401463508606, 0.006671129260212183, 0.008728899993002415, 0.010504630394279957, 0.00606940733268857, 0.03506495803594589, 0.0362837016582489, 0.020236298441886902, 0.02893964946269989, 0.01744883507490158, 0.006451593711972237, 0.019437991082668304, 0.024088697507977486, 0.012538979761302471, 0.03488847240805626, 0.06832728534936905, 0.0], [0.01601208932697773, 0.00470008747652173, 0.005945990793406963, 0.0008656787103973329, 0.0045703500509262085, 0.0013198615051805973, 0.004704649560153484, 0.0006897367420606315, 0.0038875064346939325, 0.0028471953701227903, 0.0054022870026528835, 0.0038883639499545097, 0.0027182570192962885, 0.008452564477920532, 0.003860913682729006, 0.003161830361932516, 0.008288874290883541, 0.0011015144409611821, 0.007628091145306826, 0.0031183729879558086, 0.004364403430372477, 0.0023756278678774834, 0.0018243910744786263, 0.0008166000479832292, 0.0026167193427681923, 0.008472103625535965, 0.0006033903337083757, 0.002891628770157695, 0.0025646148715168238, 0.0007065396057441831, 0.0018421221757307649, 0.003847255604341626, 0.006178941112011671, 0.018547890707850456, 0.001569555839523673, 0.004273818340152502, 0.0021449823398143053, 0.01668945513665676, 0.0051183332689106464, 0.0035700101871043444, 0.0033062559086829424, 0.0029095385689288378, 0.006080952472984791, 0.01103549636900425, 0.004986383020877838, 0.004640577360987663, 0.005366900470107794, 0.006636205594986677, 0.0025367974303662777, 0.005776362027972937, 0.004109233617782593, 0.006411102134734392, 0.014279170893132687, 0.004027200862765312, 0.002522723050788045, 0.010840379633009434, 0.008320470340549946, 0.0025174806360155344, 0.004414176102727652, 0.006768043618649244, 0.002501776674762368, 0.0021146037615835667, 0.004382540937513113, 0.005707969423383474, 0.0015887836925685406, 0.001131505356170237, 0.007634766399860382, 0.038540687412023544, 0.023571528494358063, 0.008479509502649307, 0.018489018082618713, 0.009318286553025246, 0.011472513899207115, 0.010345209389925003, 0.01819647289812565, 0.011175566352903843, 0.03168212249875069, 0.021850991994142532, 0.007703691255301237, 0.01641855202615261, 0.009413233958184719, 0.018149400129914284, 0.0253282580524683, 0.020377513021230698, 0.019998904317617416, 0.011991465464234352, 0.009652214124798775, 0.01412893645465374, 0.02046995237469673, 0.007379170041531324, 0.03749941661953926, 0.02472768723964691, 0.016816258430480957, 0.019252801313996315, 0.01630416512489319, 0.011296544224023819, 0.010101732797920704, 0.03208902105689049, 0.01718999072909355, 0.016462165862321854, 0.055809225887060165, 0.03158776834607124]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x2826832bce0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting the attention pattern\n",
    "cv.attention.attention_patterns(tokens=tokens_input, attention=attention_pattern.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b024fb9-0d6a-4df4-865a-785cf972542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://platform.openai.com/playground/p/a6smfu5HM5HcPWWuHim9pVOq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1b64b-ca19-4483-a986-d3c8c1c0437c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
